[["index.html", "Lab manual QuantRMA Preface Important notes", " Lab manual QuantRMA Original authors: Matthew J. C. Crump, Anjali Krishnan, Stephen Volz, and Alla Chavarga Adapted for EUC by Thomas Hulst and Thanos Kostopoulos Last Compiled 2021-01-24 Preface Important notes This is the lab manual for Quantitative Research Methods &amp; Analysis at EUC. As with the textbook, this manual was adapted from “Answering questions with data” by Mattew J.C. Crump. The original text is part of a larger OER (Open Educational Resource) course for teaching undergraduate statistics in psychology. As such, the text assumes you are a psychology student and many of the examples are drawn from the field of psychology. This does not mean that this course is only useful for you if you have an interest in psychology. The field of psychology will serve as a vehicle to teach you important concepts and skills in quantitative research methods and data analysis, but the concepts and skills taught are universal. This manual provides the exercises we will work on during labs. We use open-data sets that are usually paired with a primary research article. The manual is a free and open resource. See below for more information about copying, making change, or contributing to the lab manual. Attributions The original lab manual was authored by Matt Crump with exercises adapted and expanded from Open Stats Labs. CC BY-SA 4.0 license All resources are released under a creative commons licence CC BY-SA 4.0. Click the link to read more about the license, or read more below: This license means that you are free to: Share: copy and redistribute the material in any medium or format Adapt: remix, transform, and build upon the material for any purpose, even commercially. The licensor cannot revoke these freedoms as long as you follow the license terms. Under the following terms: Attribution: You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use. ShareAlike: If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original. No additional restrictions: You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits. "],["getting-started-adapted1.html", "Getting started1 0.1 Why R? 0.2 Downloading and installing R 0.3 Downloading and installing RStudio 0.4 Understanding RStudio 0.5 How to complete the labs", " Getting started1 In this course we will be using R as a tool to analyze data, and as a tool to help us gain a better understanding of what our analyses are doing. Throughout each lab we will show you how to use R to solve specific problems, and then you will use the examples to solve assignments. R is a very deep programming language, and in many ways we will only be skimming the surface of what R can do. Along the way, there will be many pointers to more advanced techniques that interested students can follow to become experts in using R for data-analysis, and computer programming in general. R is primarily a computer programming language for statistical analysis. It is free, and open-source (i.e. many people contribute to developing it), and runs on most operating systems. It is a powerful language that can be used for all sorts of mathematical operations, data-processing, analysis, and graphical display of data. I even used R to write this lab manual. And, I use R all the time for my own research, because it makes data-analysis fast, efficient, transparent and reproducible. 0.1 Why R? There are lots of different options for using computers to analyze data, so why use R?2 The options all have pros and cons, and can be used in different ways to solve a range of different problems. Some software allows you to load in data, and then analyze the data by clicking different options in a menu. This can sometimes be fast and convenient. For example, once the data is loaded, all you have to do is click a couple buttons to analyze the data! However, many aspects of data-analysis are not so easy. For example, particular analyses often require that the data be formatted in a particular way so that the program can analyze it properly. Often times when a researcher wants to ask a new question of an existing data set, they have to spend time re-formatting the data. If the data is large, then reformatting by hand is very slow, and can lead to errors. Another option, is to use a scripting language to instruct the computer how reformat the data. This is very fast and efficient. R provides the ability to do everything all in one place. You can load in data, reformat it any way you like, then analyze it anyway you like, and create beautiful graphs and tables (publication quality) to display your findings. 0.2 Downloading and installing R Okay, enough with the sales pitch. The website for downloading R is: https://cloud.r-project.org. At the top of the page – under the heading “Download and Install R” – you’ll see separate links for Mac users, Windows users, and Linux users. If you follow the relevant link, you’ll see that the online instructions are pretty self-explanatory, but I’ll walk you through the installation anyway. 0.2.1 Installing R on a Mac The CRAN (Comprehensive R Archive Network) homepage changes from time to time, and it’s not particularly pretty, or all that well-designed quite frankly. But it’s not difficult to find what you’re after. When you click on the (Mac) OS X link, you should find yourself on a page with the title “R for Mac OS X.” There’s a fairly prominent link on the page under “Latest release” called “R-x.x.x.pkg” (where the x.x.x is replaced by the most current version number), which is the one you want. Click on that link and you’ll start downloading the installer file, which is (not surprisingly) called R-x.x.x.pkg. Once you’ve downloaded R-x.x.x.pkg, all you need to do is open it by double clicking on the package file. The installation should go smoothly from there: just follow all the instructions just like you usually do when you install something. Once it’s finished, you’ll find a file called R.app in the Applications folder. You can now open up R in the usual way if you want to, but what I’m going to suggest is that instead of doing that you should now install RStudio (see this section for instructions). 0.2.2 Installing R on a Windows PC You’ll find a link at the top of the page with the text “Download R for Windows.” If you click on that, it will take you to a page that offers you a few options. Again, at the very top of the page you’ll be told to click on a link that says to click here if you’re installing R for the first time. This will take you to a page that has a prominent link at the top called “Download R x.x.x for Windows” (where the x.x.x is replaced by the most current version number). That’s the one you want. Click on that and your browser should start downloading a file called R-x.x.x-win.exe. Once you’ve downloaded the file, double click to install it. As with any software you download online, Windows will ask you some questions about whether you trust the file and so on. After you click through those, it’ll ask you where you want to install it, and what components you want to install. The default values should be fine for most people, so again, just click through. Once all that is done, you should have R installed on your system. You can access it from the Start menu, or from the desktop if you asked it to add a shortcut there. You can now open up R in the usual way if you want to, but what I’m going to suggest is that instead of doing that you should now install RStudio (see this section for instructions). 0.2.3 Installing R on a Linux PC Honestly, if you are working on a Linux PC, you can probably figure this out yourself. If you have trouble installing R on your Linux box, please see the course coordinator during office hours. Once you’ve got R installed, you can run it from the command line just by typing R. However, if you’re feeling envious of Windows and Mac users for their fancy GUIs, you can download RStudio too (see this section for instructions). 0.3 Downloading and installing RStudio Okay, so regardless of what operating system you’re using, the next thing we need to do is download and install RStudio. To understand why we install another program in addition to R, you need to understand a little bit more about R itself. The term R doesn’t really refer to a specific application on your computer. Rather, it refers to the underlying statistical language. You can use this language through lots of different applications. When you install R initially, it comes with one application that lets you do this: it’s the R.exe application on a Windows machine, and the R.app application on a Mac. But that’s not the only way to do it. There are lots of different applications that you can use that will let you interact with R. One of those is called RStudio, and it’s the one I’m going to suggest that you use. RStudio provides a clean, professional interface to R that I find much nicer to work with than either the Windows or Mac defaults. Like R itself, RStudio is free software: you can find all the details on their website. Download RStudio here: http://www.rstudio.com When you visit the RStudio website, you’ll probably be struck by how much cleaner and simpler it is than the CRAN website, and how obvious it is what you need to do: click the button that says “Download”3. When you click on the download button on the homepage it will ask you to choose whether you want the desktop version or the server version. You want the desktop version. After choosing the desktop version it will take you to a page (http://www.rstudio.org/download/desktop) that shows several possible downloads: there’s a different one for each operating system. However, the nice people at RStudio have designed the webpage so that it automatically recommends the download that is most appropriate for your computer. Click on the appropriate link, and the RStudio installer file will start downloading. Once it’s finished downloading, open the installer file in the usual way to install RStudio. After it’s finished installing, you can start R by opening RStudio. You don’t need to open R.app or R.exe in order to access R. RStudio will take care of that for you. To illustrate what RStudio looks like, Figure 0.1 shows a screenshot of an R session in progress. In this screenshot, you can see that it’s running on a Mac, but it looks almost identical no matter what operating system you have. The Windows version looks more like a Windows application (e.g., the menus are attached to the application window and the colour scheme is slightly different), but it’s more or less identical. There are a few minor differences in where things are located in the menus (I’ll point them out as we go along) and in the shortcut keys, because RStudio is trying to “feel” like a proper Mac application or a proper Windows application, and this means that it has to change its behaviour a little bit depending on what computer it’s running on. Even so, these differences are very small. One final note: the website RStudio Cloud even allows you to run R scripts in the cloud, so you can also practice R from your web-browser, although this has some limitations (most importantly: the amount of hours you can use R in the cloud is limited for free accounts). It is therefore highly recommended to do your course work on your personal device, but RStudio Cloud can help you out in a pinch. 0.4 Understanding RStudio Figure 0.1: The RStudio workspace 0.4.1 Console When you open up RStudio you will see three or four main windows (the placement of each are configurable). In the above example, the bottom left window is the command line (terminal or console) for R. Let’s focus on the console for now. The console is used to directly enter commands into R. There probably is a whole lot of text that doesn’t make much sense. It should look something like this: R version 4.0.2 (2020-06-22) -- &quot;Taking Off Again&quot; Copyright (C) 2020 The R Foundation for Statistical Computing Platform: x86_64-apple-darwin17.0 (64-bit) R is free software and comes with ABSOLUTELY NO WARRANTY. You are welcome to redistribute it under certain conditions. Type &#39;license()&#39; or &#39;licence()&#39; for distribution details. Natural language support but running in an English locale R is a collaborative project with many contributors. Type &#39;contributors()&#39; for more information and &#39;citation()&#39; on how to cite R or R packages in publications. Type &#39;demo()&#39; for some demos, &#39;help()&#39; for on-line help, or &#39;help.start()&#39; for an HTML browser interface to help. Type &#39;q()&#39; to quit R. &gt; Most of this text is pretty uninteresting, and when doing real data analysis you’ll never really pay much attention to it. The important part of it is this… &gt; … which has a flashing cursor next to it. That’s the command prompt. When you see this, it means that R is waiting patiently for you to do something! One of the easiest things you can do with R is use it as a simple calculator, so it’s a good place to start. For instance, try typing 10 + 20, and hitting enter.4 When you do this, you’ve entered a command, and R will “execute” that command. What you see on screen now will be this: &gt; 10 + 20 [1] 30 Not a lot of surprises in this extract. But there’s a few things worth talking about, even with such a simple example. Firstly, it’s important that you understand how to read the extract. In this example, what I typed was the 10 + 20 part. I didn’t type the &gt; symbol: that’s just the R command prompt and isn’t part of the actual command. And neither did I type the [1] 30 part. That’s what R printed out in response to my command. Secondly, it’s important to understand how the output is formatted. Obviously, the correct answer to the sum 10 + 20 is 30, and not surprisingly R has printed that out as part of its response. But it’s also printed out this [1] part, which probably doesn’t make a lot of sense to you right now. You’re going to see that a lot. I’ll talk about what this means in a bit more detail later on, but for now you can think of [1] 30 as if R were saying “the answer to the 1st question you asked is 30.” The console is useful for entering single lines of code and running them. Often times this occurs when you are learning how to correctly execute a line of code in R. Your first few attempts may be incorrect resulting in errors, but trying out different variations on your code in the command line can help you produce the correct code. Pressing the up arrow while in the console will scroll through the most recently executed lines of code. 0.4.2 Script Editor The top left corner contains the script editor. This is a simple text editor for writing and saving R scripts with many lines. Several tabs can be opened at once, with each tab representing a different R script. R scripts can be saved from the editor (resulting in a .R file). Whole scripts can be run by copy and pasting them into the console and pressing enter or “sourcing” them with the source button (light blue arrow). Sourcing will run all the code in your script without the need to copy/paste. Alternatively, you can highlight portions of the script that you want to run (in the script editor) and pressing the button for running the current line/section: green arrow pointing right. 0.4.3 Workspace and History The top right panel contains (at least) two tabs, one for the workspace and another for history. The workspace lists out all of the variables and functions that are currently loaded in R’s memory. You can inspect each of the variables by clicking on them. This is generally only useful for variables that do not contain large amounts of information. The history tab provides a record of the recent commands executed in the console. 0.4.4 File, Plot, Packages, Help The bottom-right window has four tabs for files, plots, packages, and help. The files tab allows browsing of the computers file directory. An important concept in R is the current working directory. This is file folder that R points to by default. Many functions in R will save things directly to this directory, or attempt to read files from this directory. The current working directory can be changed by navigating to the desired folder in the file menu, and then clicking on the more option to set that folder to the current working directory. This is especially important when loading data into R. The current working directory should be set to the folder containing the data to be inputted into R. The plots tab will show recent plots and figures made in R. The packages tab lists the current R libraries loaded into memory, and provides the ability to download and enable new R packages (more about that later). The help menu is an invaluable tool. Here, you can search for individual R commands to see examples of how they are used. Sometimes the help files for individual commands are opaque and difficult to understand, so it is necessary to do a Google search to find better examples of using these commands. 0.4.5 Installing libraries When you install R and RStudio, you get what is called Base R. Base R contains many libraries that allow you to conduct statistical analyses. Because R is free and open-source, many other developers have created add-on libraries that extend the functionality of R. We use some of these libraries, and you need to install them before you can do the labs. For example, in any of the labs, whenever you see a line code that uses the word library like this library(\"libraryname\"), this line of code telling R to load up that library so it can be used. The libraryname would be replaced with the actual name of the library. For example, you will see code like this in the labs: library(ggplot2) This line of code is saying that the ggplot2 library needs to be loaded (ggplot2 is a library which allows you to generate beautiful graphs and figures). However, before a library can be loaded, it needs to be installed. Fortunately, we can tell R to install all of the packages we need for this course in one go. Copy the following lines of code into the console, and press enter. install.packages(&quot;tidyverse&quot;) install.packages(&quot;gapminder&quot;) install.packages(&quot;ggpubr&quot;) install.packages(&quot;knitr&quot;) install.packages(&quot;rmarkdown&quot;) install.packages(&quot;bookdown&quot;) Note you can select all of the lines at once, then copy them, then paste all of them into the console, and press enter to run them all. After each of the packages are installed, you will then be able to load them using library(). You can see the installed packages by pressing the packages tab in the bottom right window. From this tab you can also update and install packages by clicking the update or install button respectively. 0.5 How to complete the labs Each of the labs focuses on particular data-analysis problems, from graphing data, computing descriptive statistics, to running inferential tests. Additionally, we will discuss important research design concepts. 0.5.1 R project To answer the questions during the labs, we will work in RStudio using an R project. An R project is a very useful way of organizing your files all in one place so you can find them later. When you double-click an R project file to open it, RStudio automatically loads and restores your last session. We have made an R project specifically for the labs that can be downloaded here or on Canvas. Download the .zip file and unzip (unarchive) it in a folder you can easily access. In the folder you unzip the file you should find the following: A folder titled “Labs_Template” Inside the folder you will see the “Labs.proj” project file and the template for the first lab A data folder containing data files for the labs By double clicking and opening the R project file, you make sure you have everything set up and are working in the correct working directory for the labs. 0.5.2 RMarkdown During the labs, you will write your notes and answers in a .Rmd (RMarkdown) file. The RMarkdown template file for the first lab is already included and can be found in your Labs_Template folder. We admit that at the beginning, RMarkdown documents might seem a little bit confusing, but you will find they are extremely useful and flexible. Basically, what RMarkdown allows you to do is combine two kinds of writing, 1) writing R code to conduct analyses, and 2) writing normal text, with headers, sub-headers, and paragraphs. You can think of this like a lab journal, that contains both your writing about what you are doing (e.g., notes to self), and the code that you use for analysis. Additionally, when your code does something like make a graph, or run a statistical test, you can ask RMarkdown to print the results.5 You complete each lab by documenting your progression through each of the parts of the lab in the RMarkdown template. At the end of each lab you will “knit” the RMarkdown file to a Word document (knitting is a term for making your documents look prettier) and upload the result to Canvas. By doing this, you will become familiar with how R and RStudio works, and how to create documents that preserve both the code and your notes all in one place. This getting started guide was adapted from the lab manual by Matthew Crump and Learning statistics with R by Danielle Navarro.↩︎ Other well-known statistical software packages are SPSS, SAS, JASP, Julia, MATLAB, Python with SciPy packages and the list goes on.↩︎ This is probably no coincidence: the people who design and distribute the core R language itself are focused on technical stuff. And sometimes they almost seem to forget that there’s an actual human user at the end. The people who design and distribute RStudio are focused on user interface. They want to make R as usable as possible. The two websites reflect that difference.↩︎ Seriously. If you’re in a position to do so, open up R and start typing. The simple act of typing it rather than “just reading” makes a big difference. It makes the concepts more concrete, and it ties the abstract ideas (programming and statistics) to the actual context in which you need to use them. Statistics is something you do, not just something you read about in a textbook.↩︎ The RMarkdown website has an excellent tutorial that is well worth checking out in your own time: https://rmarkdown.rstudio.com/lesson-1.html↩︎ "],["week-1-introductionadapted2.html", " 1 Week 1: Introduction6 1.1 Learning goals 1.2 Getting started 1.3 Part one: research methods 1.4 Part two: introduction to R", " 1 Week 1: Introduction6 This first lab consists of two parts. In the first part we will work on several exercises related to the readings about research methods. In the second part you be introduced to basic concepts in R. This lab assumes you have read the required readings of Week 1 and completed the Getting started guide. You will be completing each lab by writing your notes and code in an R Markdown document. You should have setup your files as described in this part of the Getting started section. At the end of this lab you are asked to individually upload your document to Canvas. If you finish before the time is up, you can start with the required readings of Week 2 or help out your fellow students. You can also have a look at the instructions for the first assignment and sign up for an assignment group. If you are unable to finish the exercises during the lab, continue working on them at home and discuss the exercises with your peers. You should upload your document to Canvas by Monday 23:59. The exercises will not be graded, and you will not receive personal feedback on your answers, but they should show a good effort trying to complete the exercises. The answers to the exercises will be uploaded to Canvas every Monday night. If you still have questions after finishing the exercises and reviewing the answer key, please visit the office hours on Wednesday’s. 1.1 Learning goals During this lab you will do the following: Discuss fundamental concepts of research methods and design Take your first steps in R and RStudio 3 Learn how to knit an RMarkdown document Learn about operators, functions, variables and comments in R Learn about getting help in R and debugging common errors 1.2 Getting started Follow the steps below to get started. Double-click the “Labs.Rproj” file in the Labs_Template directory (i.e., the place where you downloaded and ) RStudio should now start If you click the files tab, you should some files and a data folder inside the “Labs_Template” folder Click the lab template file (Lab01_Introduction.Rmd) and it will load into the editor window You should keep your notes, copy/paste R code, and answer the questions of this lab in the lab RMarkdown document When we made this course, we assumed that most students would be unfamiliar with R and RStudio, and might even be frightened of it. Don’t worry. It’s going to be way easier than you think. We know that it will seem challenging at first. But, we think that with lots of working examples, you will get the hang of it, and by the end of the course you will be able to do things you might never have dreamed you can do. It’s really a fantastic skill to learn, even if you aren’t planning on going on to do research. If anything during this lab is unclear, please do not hesitate to ask your tutor. 1.3 Part one: research methods Discuss the questions about research methods below in groups of 3 and register the answers the R Markdown template in RStudio (Lab01_Introduction.Rmd). 1.3.1 Question 1 In the required readings of this week we called to process of clarifying abstract concepts and translating them into specific, observable measures operationalization. Operationalization involves both a nominal and an operational definition. Describe in your own words what these terms mean. 1.3.2 Question 2 To make sure you are able to submit your answers at the end of this lab, try to “knit” your R Markdown file by pressing the “Knit” button: Knitting creates a formatted document which can be displayed by other programs. By default, the document is knitted as a .html file (which can be read by any web browser), but you can also knit your RMarkdown documents as a Word document (.docx). To do so, press the downward arrow next to the knitting symbol and select “Knit to Word.” For your lab submission, you should submit a .docx file. 1.3.3 Question 3 Two different definitions of emotional well-being are provided by the Mental Health Foundation. For each of the following definitions, decide whether it constitutes a nominal or an operational definition: “A positive sense of well-being which enables an individual to be able to function in society and meet the demands of everyday life.” “People in good mental health have the ability to recover effectively from illness, change or misfortune.” 1.3.4 Question 4 Two different definitions of financial literacy can be found in literature. For each of the following definitions, decide whether it constitutes a nominal or an operational definition: “The ability to read, analyze, manage and communicate about the personal financial conditions that affect material well-being.” “The ability to manage effectively personal savings, credits and borrowed money as well as personal investments.” 1.3.5 Question 5 Suppose you want to study financial literacy, given the numerous benefits it brings to society, and given the documented lack of financial education. Would you use the following operational definition of financial literacy: “The ability to correctly predict short term fluctuations in the stock market?” 1.3.6 Question 6 The graph below is a visual representation of the concepts of measure validity and reliability. Figure 1.1: A visual representation of the concepts measure validity and reliability. Imagine the theoretical construct you want to measure is the bullseye of the dartboard and the dots represent an attempt at measurement. Illustration adapted from an illustration by Nevit Dilmen, Wikimedia Commons. For each one of the three statements below, indicate whether it corresponds to dart board A, B, C or none. The measure of our concept is valid, but not reliable. The measure of our concept is reliable, but not valid. The measure of our concept is neither valid, not reliable. The measure of our concept is both valid and reliable. 1.3.7 Question 7 The National Health Care Institute of the Netherlands partners with local schools to provide a weekly physical exercise program for children ages 6-14. The sessions are designed to last throughout the whole academic year, and they will take place in afternoon hours. They also consist of both a theoretical and a practical part. In the theoretical part, volunteers strive to increase children’s exercise habits by teaching them about the benefits of regular exercise, whereas in the practical part, they organize various age-appropriate sports activities for children to participate in. Changes in exercise habits are measured via a questionnaire at the end of the program. However, the program manager is concerned that the questionnaire is not producing high-quality observations, particularly for questions that ask children about their exercise habits before participating in the program. Assuming the problem is with measurement and not with the program design: What is the most likely measurement problem? Reliability or validity? What type of error is most likely producing this problem? Constant error, random error and/or correlated error? How might the program address this measurement problem? 1.3.8 Question 8 The Dutch Environmental Assessment Agency aims to identify sections of Dutch rivers for stream bank restoration. The goal of this work is to create stream bank conditions that can lead to eventual water quality improvements. Crews of national service volunteers implement remediation in accordance with the waterway management plan, including removal of trash and debris from stream banks, removal of invasive plants, reintroduction of native plants, and erosion abatement. Land managers from the Ministry of Infrastructure and Water Management inspect project sites within two weeks of project completion. The assessment instrument used by land managers contains checkbox items to indicate whether various remediation actions were taken but does not provide a way to assess the quality of these remediation actions with respect to environmental standards. This problem should be of high concern to the land managers, given the fact that high quality environmental standards are hard to meet, even when all the appropriate actions have been taken. Assuming the problem is with measurement and not with the program design: What is the most likely measurement problem? Reliability or validity? What type of error is most likely producing this problem? Constant error, random error and/or correlated error? How might the program address this measurement problem? 1.4 Part two: introduction to R This part of the lab manual will introduce you to the very basics of R. You are urged to follow along with the examples in your own RStudio window. The answers to the exercises can be registered in the R Markdown document of this lab. During this part of the lab, we’ll spend a bit of time using R as a simple calculator, since that’s the easiest thing to do with R, just to give you a feel for what it’s like to work in R. In the Getting started guide we learned to execute our first command in R, by typing 10 + 20 in the console and pressing enter. Try it out in RStudio: 10+20 ## [1] 30 1.4.1 Doing simple calculations with R First, let’s learn how to use one of the most powerful piece of statistical software in the world as a €2 calculator. So far, all we know how to do is addition. Clearly, a calculator that only did addition would be a bit stupid, so I should tell you about how to perform other simple calculations using R. But first, some more terminology. Addition is an example of an “operation” that you can perform (specifically, an arithmetic operation), and the operator that performs it is +. To people with a programming or mathematics background, this terminology probably feels pretty natural, but to other people it might feel like I’m trying to make something very simple (addition) sound more complicated than it is (by calling it an arithmetic operation). To some extent, that’s true: if addition was the only operation that we were interested in, it’d be a bit silly to introduce all this extra terminology. However, as we go along, we’ll start using more and more different kinds of operations, so it’s probably a good idea to get the language straight now, while we’re still talking about very familiar concepts like addition! 1.4.1.1 Adding, subtracting, multiplying and dividing So, now that we have the terminology, let’s learn how to perform some arithmetic operations in R. To that end, the table below lists the operators that correspond to the basic arithmetic we learned in primary school: addition, subtraction, multiplication and division. operation operator example input example output addition + 10 + 2 12 subtraction - 9 - 3 6 multiplication * 5 * 5 25 division / 10 / 3 3 power ^ 5 ^ 2 25 As you can see, R uses fairly standard symbols to denote each of the different operations you might want to perform: addition is done using the + operator, subtraction is performed by the - operator, and so on. So if I wanted to find out what 57 times 61 is (and who wouldn’t?), I can use R instead of a calculator, like so: 57 * 61 ## [1] 3477 So that’s handy. 1.4.1.2 Doing calculations in the right order Okay. At this point, you know how to take one of the most powerful pieces of statistical software in the world, and use it as a €2 calculator. And as a bonus, you’ve learned a few very basic programming concepts. That’s not nothing (you could argue that you’ve just saved yourself €2) but on the other hand, it’s not very much either. In order to use R more effectively, we need to introduce more programming concepts. In most situations where you would want to use a calculator, you might want to do multiple calculations. R lets you do this, just by typing in longer commands. 1 + 2 * 4 ## [1] 9 Clearly, this isn’t a problem for R either. However, it’s worth stopping for a second, and thinking about what R just did. Clearly, since it gave us an answer of 9 it must have multiplied 2 * 4 (to get an interim answer of 8) and then added 1 to that. But, suppose it had decided to just go from left to right: if R had decided instead to add 1+2 (to get an interim answer of 3) and then multiplied by 4, it would have come up with an answer of 12. To answer this, you need to know the order of operations that R uses. It’s actually the same order that (most of) you got taught when you were in high school: the “BEDMAS” order7. That is, first calculate things inside Brackets (), then calculate Exponents ^, then Division / and Multiplication *, then Addition + and Subtraction -. So, to continue the example above, if we want to force R to calculate the 1+2 part before the multiplication, all we would have to do is enclose it in brackets: (1 + 2) * 4 ## [1] 12 This is a fairly useful thing to be able to do. The only other thing I should point out about order of operations is what to expect when you have two operations that have the same priority: that is, how does R resolve ties? For instance, multiplication and division are actually the same priority, but what should we expect when we give R a problem like 4 / 2 * 3 to solve? If it evaluates the multiplication first and then the division, it would calculate a value of two-thirds. But if it evaluates the division first it calculates a value of 6. The answer, in this case, is that R goes from left to right, so in this case the division step would come first: 4 / 2 * 3 ## [1] 6 All of the above being said, it’s helpful to remember that brackets always come first. So, if you’re ever unsure about what order R will do things in, an easy solution is to enclose the thing you want it to do first in brackets. There’s nothing stopping you from typing (4 / 2) * 3. By enclosing the division in brackets we make it clear which thing is supposed to happen first. In this instance you wouldn’t have needed to, since R would have done the division first anyway, but when you’re first starting out it’s better to make sure R does what you want! 1.4.1.3 Arithmetics exercises Answer these and the following exercises in the codeblocks of the R Markdown template in RStudio (Lab01_Introduction.Rmd). Take your favorite number to the third power. Calculate the number of seconds in a year, on the simplifying assumption that a year contains exactly 365 days. Use R to calculate solution to 6/2*(1+2). Why is the solution not 1? 1.4.2 Using functions to do calculations The symbols +, -, * and so on are examples of operators. As we’ve seen, you can do quite a lot of calculations just by using these operators. However, in order to do more advanced calculations (and later on, to do actual statistics), you’re going to need to start using functions. To get started, suppose I wanted to take the square root of 225. The square root, in case your high school maths is a bit rusty, is just the opposite of squaring a number. So, for instance, since “5 squared is 25” I can say that “5 is the square root of 25.” The usual notation for this is \\[ \\sqrt{25} = 5 \\] though sometimes you’ll also see it written like this \\(25^{0.5} = 5.\\) To calculate the square root of 25, I can do it in my head pretty easily, since I memorised my multiplication tables when I was a kid. It gets harder when the numbers get bigger, and pretty much impossible if they’re not whole numbers. This is where something like R comes in very handy. Let’s say I wanted to calculate \\(\\sqrt{225}\\), the square root of 225. There’s two ways I could do this using R. Firstly, since the square root of 255 is the same thing as raising 225 to the power of 0.5, I could use the power operator ^, just like we did earlier: 225 ^ 0.5 ## [1] 15 However, there’s a second way that we can do this, since R also provides a square root function: sqrt(). To calculate the square root of 255 using this function, what I do is insert the number 225 in the parentheses. That is, the command I type is this: sqrt(225) ## [1] 15 When we use a function to do something, we generally refer to this as calling the function, and the values that we type into the function (there can be more than one) are referred to as the arguments of that function. Obviously, the sqrt() function doesn’t really give us any new functionality, since we already knew how to do square root calculations by using the power operator ^, though I do think it looks nicer when we use sqrt(). However, there are lots of other functions in R: in fact, almost everything of interest that we’ll use during our statistical analyses is an R function of some kind. For example, one function that can come in handy is the absolute value function. Compared to the square root function, it’s extremely simple: it just converts negative numbers to positive numbers, and leaves positive numbers alone. Calculating absolute values in R is pretty easy, since R provides the abs function that you can use for this purpose. For instance: abs(-13) ## [1] 13 Before moving on, it’s worth noting that – in the same way that R allows us to put multiple operations together into a longer command, like 1 + 2*4 for instance – it also lets us put functions together and even combine functions with operators if we so desire. For example, the following is a perfectly legitimate command: sqrt( 1 + abs(-8) ) ## [1] 3 When R executes this command, starts out by calculating the value of abs(-8), which produces an intermediate value of 8. Having done so, the command simplifies to sqrt( 1 + 8 ). 1.4.2.1 Multiple arguments There’s two more fairly important things that you need to understand about how functions work in R, and that’s the use of “named” arguments, and default values\" for arguments. Not surprisingly, that’s not to say that this is the last we’ll hear about how functions work, but they are the last things we desperately need to discuss in order to get you started. To understand what these two concepts are all about, I’ll introduce another function. The round() function can be used to round some value to the nearest whole number. For example, I could type this: round(3.1415) ## [1] 3 Pretty straightforward, really. However, suppose I only wanted to round it to two decimal places: that is, I want to get 3.14 as the output. The round() function supports this, by allowing you to input a second argument to the function that specifies the number of decimal places that you want to round the number to. In other words, I could do this: round(3.1415, 2) ## [1] 3.14 What’s happening here is that I’ve specified two arguments: the first argument is the number that needs to be rounded (i.e., 3.1415), the second argument is the number of decimal places that it should be rounded to (i.e., 2), and the two arguments are separated by a comma. 1.4.2.2 Argument names In this simple example, it’s quite easy to remember which one argument comes first and which one comes second, but for more complicated functions this is not easy. Fortunately, most R functions make use of argument names. For the round() function, for example the number that needs to be rounded is specified using the x argument, and the number of decimal points that you want it rounded to is specified using the digits argument. Because we have these names available to us, we can specify the arguments to the function by name. We do so like this: round(x = 3.1415, digits = 2) ## [1] 3.14 Notice that this is kind of similar in spirit to variable assignment, except that I used = here, rather than &lt;-. In both cases we’re specifying specific values to be associated with a label. However, there are some differences between what I was doing earlier on when creating variables, and what I’m doing here when specifying arguments, and so as a consequence it’s important that you use = in this context. As you can see, specifying the arguments by name involves a lot more typing, but it’s also a lot easier to read. Because of this, the commands in this lab manual will usually specify arguments by name, since that makes it clearer to you what I’m doing. However, one important thing to note is that when specifying the arguments using their names, it doesn’t matter what order you type them in. But if you don’t use the argument names, then you have to input the arguments in the correct order. In other words, these three commands all produce the same output… round(3.1415, 2) ## [1] 3.14 round(x = 3.1415, digits = 2) ## [1] 3.14 round(digits = 2, x = 3.1415) ## [1] 3.14 but this one does not… round( 2, 3.14165 ) ## [1] 2 1.4.2.3 Getting help with functions How do you find out what the correct order is or what arguments a function uses? There’s a few different ways, but the easiest one is to look at the help documentation for the function. You can look up the documentation of any function by typing a question mark (?) and the function name as follows: ?round I have somewhat mixed feelings about the help documentation in R. On the plus side, there’s a lot of it, and it’s very thorough. On the minus side, there’s a lot of it, and it’s very thorough. There’s so much help documentation that it sometimes doesn’t help, and most of it is written with an advanced user in mind. Now, it’s probably beginning to dawn on you that there are going to be a lot of R functions, all of which have their own arguments. You’re probably also worried that you’re going to have to remember all of them! Thankfully, it’s not that bad. In fact, very few data analysts bother to try to remember all the commands. What they really do is use tricks to make their lives easier. The first trick is using the ? command shown above to display the documentation on a particular function. Another trick is to use two question marks (??) to launch a search to all mentions of the word after ?? in the R documentation. The final, and arguably most important trick, is to use the internet. If you don’t know how a particular R function works, or you want to do something in R but are unsure how, Google it. 1.4.2.4 Function exercises Use a function to calculate the square root of your favorite number. How many arguments does the function log() take? Use R to execute the following command: rep(\"hello!\",100). What does the rep() function do? Could you rewrite the command to use argument names? 1.4.3 Storing a number as a variable One of the most important things to be able to do in R (or any programming language, for that matter) is to store information in variables. Variables in R aren’t exactly the same thing as the variables we talked about in the chapter on research methods, but they are similar. At a conceptual level you can think of a variable as label for a certain piece of information, or even several different pieces of information. When doing statistical analysis in R all of your data (the variables you measured in your study) will be stored as variables in R, but as well see later in the book you’ll find that you end up creating variables for other things too. However, before we delve into all the messy details of data sets and statistical analysis, let’s look at the very basics for how we create variables and work with them. 1.4.3.1 Variable assignment using &lt;- Since we’ve been working with numbers so far, let’s start by creating variables to store our numbers. And since most people like concrete examples, let’s invent one. Suppose I’m trying to calculate how much money I’m going to make from selling my book about statistics. There’s several different numbers I might want to store. Firstly, I need to figure out how many copies I’ll sell. The book I’m writing isn’t exactly Harry Potter, so let’s assume I’m only going to sell one copy per student in my class. That’s about 200 sales, so let’s create a variable called sales. What I want to do is assign a value to my variable sales, and that value should be 200. We do this by using the assignment operator, which is &lt;-. Here’s how we do it: sales &lt;- 200 When you hit enter, R doesn’t print out any output.8 It just gives you another command prompt. However, behind the scenes R has created a variable called sales and given it a value of 200. You can check that this has happened by asking R to print the variable on screen. And the simplest way to do that is to type the name of the variable and hit enter. sales ## [1] 200 1.4.3.2 Doing calculations using variables Okay, let’s get back to my original story. In my quest to become rich, I’ve written this statistics textbook. To figure out how good a strategy this is, I’ve started creating some variables in R. In addition to defining a sales variable that counts the number of copies I’m going to sell, I can also create a variable called royalty, indicating how much money I get per copy. Let’s say that my royalties are about €7 per book: sales &lt;- 200 royalty &lt;- 7 The nice thing about variables (in fact, the whole point of having variables) is that we can do anything with a variable that we ought to be able to do with the information that it stores. That is, since R allows me to multiply 200 by 7 200 * 7 ## [1] 1400 it also allows me to multiply sales by royalty sales * royalty ## [1] 1400 As far as R is concerned, the sales * royalty command is the same as the 200 * 7 command. Not surprisingly, I can assign the output of this calculation to a new variable, which I’ll call revenue. And when we do this, the new variable revenue gets the value 1400. So let’s do that, and then get R to print out the value of revenue so that we can verify that it’s done what we asked: revenue &lt;- sales * royalty revenue ## [1] 1400 That’s fairly straightforward. A slightly more subtle thing we can do is reassign the value of my variable, based on its current value. For instance, suppose that one of my students loves the book so much that he or she donates me an extra €550. The simplest way to capture this is by a command like this: revenue &lt;- revenue + 550 revenue ## [1] 1950 In this calculation, R has taken the old value of revenue (i.e., 1400) and added 550 to that value, producing a value of 1950. This new value is assigned to the revenue variable, overwriting its previous value. In any case, we now know that I’m expecting to make €1950 off this. Hurray! 1.4.3.3 Exercises variables Assign your favorite number to the variable fav_num. Assign a sequence of numbers from 1 to 10 the variable seq_10 (hint: seq()). Multiply fav_num with seq_10 and save the result in a variable called fav_num_seq10.9 1.4.4 Using comments Another very useful feature of R is the comment character, #. It has a simple meaning in R: it tells R to ignore everything else you’ve written on the line after the # character. You won’t have much need of the # character immediately, but it’s very when writing longer scripts. For instance, if you read this: seeker &lt;- 3.1415 # create the first variable lover &lt;- 2.7183 # create the second variable keeper &lt;- seeker * lover # now multiply them to create a third one print(keeper) # print out the value of &#39;keeper&#39; } it’s a lot easier to understand what I’m doing than if I just write this: seeker &lt;- 3.1415 lover &lt;- 2.7183 keeper &lt;- seeker * lover print(keeper) Commenting makes any code a little easier to understand. 1.4.5 R is pretty stupid? There are a couple of things you should keep in mind when working with R. The first thing is that, while R is good software, it’s still software. To some extent, I’m stating the obvious here, but it’s important. The people who wrote R are smart. You, the user, are smart. But R itself is dumb. And because it’s dumb, it has to be mindlessly obedient. It does exactly what you ask it to do. There is no equivalent to “autocorrect” in R, and for good reason. When doing advanced stuff – and even the simplest of statistics is pretty advanced in a lot of ways – it’s dangerous to let a mindless automaton like R try to overrule the human user. But because of this, it’s your responsibility to be careful. Always make sure you type exactly what you mean. When dealing with computers, it’s not enough to type “approximately” the right thing. In general, you absolutely must be precise in what you say to R … like all machines it is too stupid to be anything other than absurdly literal in its interpretation. 1.4.5.1 Typos R takes it on faith that you meant to type exactly what you did type. For example, suppose that you forgot to hit the shift key when trying to type +, and as a result your command ended up being 10 = 20 rather than 10 + 20. 10 = 20 What happens when you have R try to execute this command, is that it attempts to interpret 10 = 20 as a command, and spits out an error message because the command doesn’t make any sense. When a human looks at this, and then looks down at his or her keyboard and sees that + and = are on the same key, it’s pretty obvious that the command was a typo. But R doesn’t know this, so it gets upset. And, if you look at it from its perspective, this makes sense. All that R “knows” is that 10 is a legitimate number, 20 is a legitimate number, and = is a legitimate part of the language too. In other words, from its perspective this really does look like the user meant to type 10 = 20, since all the individual parts of that statement are legitimate and it’s too stupid to realise that this is probably a typo. Therefore, R takes it on faith that this is exactly what you meant… it only “discovers” that the command is nonsense when it tries to follow your instructions, typo and all. And then it whinges, and spits out an error. Even more subtle is the fact that some typos won’t produce errors at all, because they happen to correspond to “well-formed” R commands. For instance, suppose that not only did I forget to hit the shift key when trying to type 10 + 20, I also managed to press the key next to one I meant do. The resulting typo would produce the command 10 - 20. Clearly, R has no way of knowing that you meant to add 20 to 10, not subtract 20 from 10, so what happens this time is this: 10 - 20 ## [1] -10 In this case, R produces the right answer, but to the the wrong question. 1.4.5.2 R is flexible with spacing? I should point out that there are some exceptions. Or, more accurately, there are some situations in which R does show a bit more flexibility than my previous description suggests. The first thing R is smart enough to do is ignore redundant spacing. What I mean by this is that, when I typed 10 + 20 before, I could equally have done this 10 + 20 ## [1] 30 or this 10+20 ## [1] 30 and I would get exactly the same answer. However, that doesn’t mean that you can insert spaces in any old place. For example, the startup message of R suggests you can type citation() to get some information about how to cite R. If I do so… citation() ## ## To cite R in publications use: ## ## R Core Team (2020). R: A language and environment for statistical ## computing. R Foundation for Statistical Computing, Vienna, Austria. ## URL https://www.R-project.org/. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {R: A Language and Environment for Statistical Computing}, ## author = {{R Core Team}}, ## organization = {R Foundation for Statistical Computing}, ## address = {Vienna, Austria}, ## year = {2020}, ## url = {https://www.R-project.org/}, ## } ## ## We have invested a lot of time and effort in creating R, please cite it ## when using it for data analysis. See also &#39;citation(&quot;pkgname&quot;)&#39; for ## citing R packages. … it tells me to cite the R manual (R Core Team 2020). Let’s see what happens when we try changing the spacing. If you insert spaces in between the word and the parentheses, or inside the parentheses themselves, then all is well. That is, either of these two commands citation () citation( ) will produce exactly the same response. However, what we can’t do is insert spaces in the middle of the word. If you try to do this, R gets upset: citat ion() Throughout this lab manual you will see varied uses of spacing, just to give you a feel for the different ways in which spacing can be used. We’ll try not to do it too much though, since it’s generally considered to be good practice to be consistent in how you format your commands. 1.4.5.3 R knows you’re not finished? One more thing we should point out. If you hit enter in a situation where it’s “obvious” to R that you haven’t actually finished typing the command, R is just smart enough to keep waiting. For example, if you type 10 + and then press enter, even R is smart enough to realise that you probably wanted to type in another number. So here’s what happens: &gt; 10+ + and there’s a blinking cursor next to the plus sign. What this means is that R is still waiting for you to finish. It “thinks” you’re still typing your command, so it hasn’t tried to execute it yet. In other words, this plus sign is actually another command prompt. It’s different from the usual one (i.e., the &gt; symbol) to remind you that R is going to “add” whatever you type now to what you typed last time. For example, if we then go on to type 20 and hit enter, what we get is this: &gt; 10 + + 20 [1] 30 And as far as R is concerned, this is exactly the same as if you had typed 10 + 20. Similarly, consider the citation() command that we talked about in the previous section. Suppose you hit enter after typing citation(. Once again, R is smart enough to realise that there must be more coming – since you need to add the ) character – so it waits. We can even hit enter several times and it will keep waiting: &gt; citation( + + + ) We’ll make use of this a lot in this book. A lot of the commands that we’ll have to type are pretty long, and they’re visually a bit easier to read if we break it up over several lines. If you start doing this yourself, you’ll eventually get yourself in trouble (it happens to us all). Maybe you start typing a command, and then you realise you’ve screwed up. For example, &gt; citblation( + + You’d probably prefer R not to try running this command, right? If you want to get out of this situation, just hit the ‘escape’ key.10 R will return you to the normal command prompt (i.e. &gt;) without attempting to execute the botched command. That being said, it’s not often the case that R is smart enough to tell that there’s more coming. For instance, in the same way that I can’t add a space in the middle of a word, I can’t hit enter in the middle of a word either. If we hit enter after typing citat we get an error, because R thinks we’re interested in an “object” called citat and can’t find it: &gt; citat Error: object &#39;citat&#39; not found What about if we typed citation and hit enter? In this case we get something very odd, something that we definitely don’t want, at least at this stage. Here’s what happens: citation ## function (package = &quot;base&quot;, lib.loc = NULL, auto = NULL) ## { ## dir &lt;- system.file(package = package, lib.loc = lib.loc) ## if (dir == &quot;&quot;) ## stop(gettextf(&quot;package &#39;%s&#39; not found&quot;, package), domain = NA) BLAH BLAH BLAH where the BLAH BLAH BLAH goes on for rather a long time, and you don’t know enough R yet to understand what all this gibberish actually means (of course, it doesn’t actually say BLAH BLAH BLAH - it says some other things we don’t understand or need to know that I’ve edited for length) This incomprehensible output can be quite intimidating to novice users, and unfortunately it’s very easy to forget to type the parentheses; so almost certainly you’ll do this by accident. Do not panic when this happens. Simply ignore the gibberish. As you become more experienced this gibberish will start to make sense, and you’ll find it quite handy to print this stuff out.11 But for now just try to remember to add the parentheses when typing your commands. 1.4.5.4 Common mistakes exercises Figure out what is wrong with the following R commands and try to fix them: x &lt;- 1 y &lt;- 5 x*z x &lt;- Seq(1,10) x &lt;- sqrt(seq(1,10) This is actually my favorite number: fav_num &lt;- 2.718 When you have completed all exercises and are happy with your progress today, please knit your document (as a .docx) and submit it to Canvas. If you are unable to finish the exercises during the lab, continue working on them at home and discuss the exercises with your peers. You should upload your document to Canvas by Monday 23:59. The exercises will not be graded, and you will not receive personal feedback on your answers, but they should show a good effort trying to complete the exercises. The answers to all exercises will be uploaded to Canvas every Monday night. If you still have questions after finishing the exercises and reviewing the answer key, please visit the office hours on Wednesday. If you finish before the time is up, you can start with the required readings of Week 2 or help out your fellow students. You can also have a look at the instructions for the first assignment and sign up for an assignment group. The R part of this lab was adapted from the book by Danielle Navarro↩︎ Alternatively: PEMDAS: Parentheses, Exponents, Multiplication, Division, Addition, Subtraction↩︎ If you are using RStudio, and the “environment” panel is visible when you typed the command, then you probably saw something happening there. That’s to be expected, and is quite helpful.↩︎ The output of this operation should result in a so-called vector of 10 numbers. We will encounter vectors later in the course, but basically a vector is a variable that can store multiple values.↩︎ If you’re running R from the terminal rather than from RStudio, escape doesn’t work: use CTRL-C instead.↩︎ For advanced users: yes, as you’ve probably guessed, R is printing out the source code for the function.↩︎ "],["week-2-describing-data.html", " 2 Week 2: Describing Data 2.1 Learning goals 2.2 Part one: describing data using graphs 2.3 Part two: describing data using numbers", " 2 Week 2: Describing Data The commonality between science and art is in trying to see profoundly - to develop strategies of seeing and showing. —Edward Tufte The purpose of this lab is to show you how to generate graphs and compute basic descriptive statistics, including measures of central tendency (mean, mode, median) and variation (range, variance, standard deviation). We learned in the lecture and from the textbook that data we want to answer questions of, often comes with loads of numbers. Too many numbers to look at all at once. That’s one reason we use descriptive statistics. To reduce the big set of numbers to one or two summary numbers or a pretty graph that tells us something about all of the numbers. R can produce descriptive statistics for you in many ways. We’ll go over some R basics for descriptive statistics, and then use our new found skills to ask some questions about real data. To get started, download the lab template here (right click: save as) or from Canvas. Copy the lab template to your lab folder and open Lab.proj. Note: we are going to introduce a lot of new programming concepts very quickly and you might feel overwhelmed or unsure you fully grasp the new concepts. This is completely normal when learning a new programming language. We start with simply copy/pasting and dissecting R commands as a way to familiarize you with the language. You will see that by doing this you can very quickly learn to answer interesting questions about a data set, just from changing a couple of minor things in the code examples. In our experience, this works better than expecting you to code something from scratch at the start of learning a new language. As always, there are several ways to get help when coding in R: Use the ?help or ??help functions Google your question Ask a fellow student or your tutor for additional explanations 2.1 Learning goals During this lab you will do the following: Learn how to load data into R Learn how data is structured Generate graphs using ggplot2 Compute measures of central tendency and variation using R Answer some questions about data using descriptive statistics 2.2 Part one: describing data using graphs In order to graph data, we need to have some data first… let’s figure out what movies are going to be filmed in New York City. It turns out that NYC makes a lot of data about a lot things open and free for anyone to download and look at. This is the NYC Open Data website: https://opendata.cityofnewyork.us. I searched through the data, and found a data file that lists the locations of film permits for shooting movies all throughout the Burroughs. There are multiple ways to load this data into R. If you have downloaded the Labs_Template.zip file, then you already have the data file in the data folder. Assuming you are working in your main directory (your .Rmd file is saved in the main folder that contains both the data and template files), use the following commands to load the data: library(tidyverse) nyc_films &lt;-read_csv(&quot;data/Film_Permits.csv&quot;) Try to understand what is happening in the code above. In both cases, we first load the library tidyverse. Then, we use the function read_csv() (from the tidyverse) to load the data and assign it to the variable nyc_films. If you are having issues getting the data loaded, talk to your tutor. 2.2.1 Look at the data You will be downloading and analyzing all kinds of data files this quad. We will follow the very same steps every time. The steps are to load the data, then look at it. You want to see what you’ve got. In RStudio, you will now see a variable called nyc_films in the top right-hand corner of the screen, in the environment tab. If you click this thing, it will show you the contents of the data in a new window. The data is stored in something we call a data frame. It’s R lingo, for the thing that contains the data. Notice it is shaped like a rectangle, with rows going across, and columns going up and down. It looks kind of like an excel spreadsheet if you are familiar with Excel. You can also use the R functions head() and tail() to print out the first 6 or last 6 rows of our data frame in the R console, or summary() and str() for a quick overview of our data frame: # head() prints the first 6 rows of a data frame head(nyc_films) # tail() prints the last 6 rows of a data frame tail(nyc_films) # summary() and str() show a brief summary of a data frame summary(nyc_films) str(nyc_films) Using the head(), tail() and summary() or str() functions on this data frame, you’ll see that the output in the R console doesn’t look pretty. It’s useful to know you can look at the data frame this way if you need to. But, this data frame is really big, it has 50,728 rows (or observations) and 14 columns (or variables). You can get the size of the data frame by looking in the environment tab or using the functions nrow() and ncol(): nrow(nyc_films) ## [1] 50728 ncol(nyc_films) ## [1] 14 We can also use the $ operator to request the data of a single column (i.e. variable). For example, to print the data of the first 6 rows of the Category column: head(nyc_films$Category) ## [1] &quot;Television&quot; &quot;Television&quot; &quot;Television&quot; &quot;Commercial&quot; &quot;Television&quot; ## [6] &quot;Television&quot; 2.2.2 Data exercises What are the last 6 entries of the Category column in nyc_films? What are the last 10 entries of the EventType column in nyc_films? Use fread() to only load the EventID column and assign it to a variable named nyc_films_eventid (hint: ?fread()). 2.2.3 Make plots to answer questions Let’s walk through a couple questions we might have about this data. We can see that there were 50,728 film permits made. We can also see that there are different columns telling us information about each of the film permits. For example, the Borough column lists the Borough for each request, whether it was made for: Manhattan, Brooklyn, Bronx, Queen’s, or Staten Island. 2.2.3.1 Answering our first question Where are the most film permits being requested? We can find out by using R to plot the data in a bar plot. A bar plot looks a bit like a histogram, but the bars on a bar plot represent the counts of categorical data instead of continuous data. To generate a bar plot, we first need to have R count how many film permits are made in each borough, and then make a plot where the bars represent the counts per borough. Run the following code: library(dplyr) counts &lt;- nyc_films %&gt;% group_by(Borough) %&gt;% summarize(count_of_permits = length(Borough)) You might notice two things in the code above: We are loading the library dplyr. dplyr is a library that simplifies manipulating data frames. We are using a new operator you haven’t encountered before: %&gt;%. This operator is called the ‘pipe’ operator. The pipe operator allows us to clearly express a sequence of multiple operations on a data frame. The code above first groups the data by each of the five Borough’s, and then counts the number of times each Borough occurs. The result is saved in a new variable called count. The code above is equivalent to the code below which doesn’t use the pipe operator, but assigns the outcome of an operation to an intermediate variable. library(dplyr) nyc_films_grouped &lt;- group_by(nyc_films, Borough) counts &lt;- summarize(nyc_films_grouped, count_of_permits = length(Borough)) The difference between the first or second code block might seem a bit confusing or arbitrary, as both methods generate the same result, but especially when performing multiple operations on a data frame, the pipe operator results in much more efficient and readable code. Either way, if you click on the counts variable in your environment, you will see the five boroughs listed, along with the counts for how many film permits were requested in each Borough. These are the numbers that we want to plot in a graph. 2.2.3.2 Making the plot We actually make the plot using a fantastic library called ggplot2. It is very powerful once you get the hand of it, and when you do, you will be able to make all sorts of interesting graphs. Here’s the code to make the plot: library(ggplot2) ggplot(counts, aes(x = Borough, y = count_of_permits )) + geom_bar(stat=&quot;identity&quot;) There it is, we’re done here! We can easily look at this graph, and answer our question. Most of the film permits were requested in Manhattan, followed by Brooklyn, then Queen’s, the Bronx, and finally Staten Island. 2.2.3.3 What kind of films are being made? We think you might be skeptical of what you are doing here, just copying and pasting things. Soon you’ll see how fast you can answer questions about data by copying and pasting and just making a few little changes to the code. Let’s quickly answer another question about what kinds of films are being made. The column Category, gives us some information about that. Let’s just copy paste the code we already made, and see what kinds of categories the films fall into. See if you can tell what I changed in the code to make this work: counts &lt;- nyc_films %&gt;% group_by(Category) %&gt;% summarize(count_of_permits = length(Category)) ggplot(counts, aes(x = Category, y = count_of_permits )) + geom_bar(stat=&quot;identity&quot;) OK, so this figure might look a bit weird because the labels on the bottom are running into each other. We’ll fix that in a bit. First, let’s notice the changes. I changed Borough to Category. That was the main thing. I left out a bunch of things from before. None of the library() commands are used again, and I didn’t re-run the very early code to get the data. R already has those things in it’s memory, so we don’t need to do that first. Fine, so how do we fix the graph? Good question. You probably have no idea how to do this, but googling your questions is a great way to learn R. It’s what everybody does. When you Google this question, you will likely find a lot of ways to fix your graph. The trick I used is to add the last line in the R code below. I just copy-pasted it from the solution I found on stack overflow (you will become friends with stack overflow this course, there are many solutions there to all of your questions). counts &lt;- nyc_films %&gt;% group_by(Category) %&gt;% summarize(count_of_permits = length(Category)) ggplot(counts, aes(x = Category, y = count_of_permits )) + geom_bar(stat=&quot;identity&quot;)+ theme(axis.text.x = element_text(angle = 90, hjust = 1)) 2.2.3.4 ggplot2 basics Before we go further, I want to point out some basic properties of ggplot2, just to give you a sense of how it is working. This will make more sense in a few weeks, so come back here to remind yourself. We’ll do just a bit of basics, and then move on to making more graphs, by copying/pasting and modifying existing code. The ggplot function makes use of so-called layers. Layers you say? What are these layers? Well, it draws things from the bottom up. It lays down one layer of graphics, then you can keep adding on top, drawing more things. So the idea is something like: Layer 1 + Layer 2 + Layer 3, and so on. If you want Layer 3 to be Layer 2, then you just switch them in the code. Here is a way of thinking about ggplot code ggplot(name_of_data, aes(x = name_of_x_variable, y = name_of_y_variable)) + geom_layer()+ geom_layer()+ geom_layer() What I want you to focus on in the above description is the \\(+\\) signs. What we are doing with the plus signs is adding layers to plot. The layers get added in the order that they are written (a bit like the %&gt;% operator for dataframes). If you look back to our previous code, you will see we add a geom_bar layer, then we added another layer to change the rotation of the words on the x-axis. This is how it works. BUT WAIT? How am I supposed to know and remember what to add? This is nuts! We know. You’re not supposed to know just yet, how could you? We’ll give you lots of examples where you can copy and paste, and they will work. That’s how you’ll learn for now. If you really want to read the help manual you can do that too. There’s also this useful cheatsheet. This will become useful after you already know what you are doing, but before that, it will probably just seem very confusing. However, it is pretty neat to look and see all of the different things you can do, it’s very powerful. For now, let’s the get the hang of adding things to the graph that let us change some stuff we might want to change. For example, how do you add a title? Or change the labels on the axes? Or add different colors, or change the font-size, or change the background? You can change all of these things by adding different lines to the existing code. 2.2.3.5 ylab() changes y label The last graph had count_of_permits as the label on the y-axis. That doesn’t look right. ggplot2 automatically took the label from the column name, and made it be the name on the y-axis. We can change that by adding ylab(\"text\"). We do this by adding a \\(+\\) to the last line, then adding ylab() ggplot(counts, aes(x = Category, y = count_of_permits )) + geom_bar(stat=&quot;identity&quot;) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ylab(&quot;Number of Film Permits&quot;) 2.2.3.6 xlab() changes x label Let’s slightly modify the x label too: ggplot(counts, aes(x = Category, y = count_of_permits )) + geom_bar(stat=&quot;identity&quot;) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ylab(&quot;Number of Film Permits&quot;) + xlab(&quot;Category of film&quot;) 2.2.3.7 ggtitle() adds title Let’s give our graph a title ggplot(counts, aes(x = Category, y = count_of_permits )) + geom_bar(stat=&quot;identity&quot;) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ylab(&quot;Number of Film Permits&quot;) + xlab(&quot;Category of film&quot;) + ggtitle(&quot;Number of Film permits in NYC by Category&quot;) 2.2.3.8 color() adds color Let’s make the bars different colors. To do this, we add new code to the inside of the aes() part: ggplot(counts, aes(x = Category, y = count_of_permits, color=Category )) + geom_bar(stat=&quot;identity&quot;) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ylab(&quot;Number of Film Permits&quot;) + xlab(&quot;Category of film&quot;) + ggtitle(&quot;Number of Film permits in NYC by Category&quot;) 2.2.3.9 fill() fills in color Let’s make the bars different colors. To do this, we add new code to the inside of the aes() part…Notice I’ve started using new lines to make the code more readable. ggplot(counts, aes(x = Category, y = count_of_permits, color=Category, fill= Category )) + geom_bar(stat=&quot;identity&quot;) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ylab(&quot;Number of Film Permits&quot;) + xlab(&quot;Category of film&quot;) + ggtitle(&quot;Number of Film permits in NYC by Category&quot;) 2.2.3.10 Get rid of the legend Sometimes you just don’t want the legend on the side, to remove it add theme(legend.position=\"none\") ggplot(counts, aes(x = Category, y = count_of_permits, color=Category, fill= Category )) + geom_bar(stat=&quot;identity&quot;) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ylab(&quot;Number of Film Permits&quot;) + xlab(&quot;Category of film&quot;) + ggtitle(&quot;Number of Film permits in NYC by Category&quot;) + theme(legend.position=&quot;none&quot;) 2.2.3.11 theme_classic() makes white background The rest is often just visual preference. For example, the graph above has this grey grid behind the bars. For a clean classic no nonsense look, use theme_classic() to take away the grid. ggplot(counts, aes(x = Category, y = count_of_permits, color=Category, fill= Category )) + geom_bar(stat=&quot;identity&quot;) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ylab(&quot;Number of Film Permits&quot;) + xlab(&quot;Category of film&quot;) + ggtitle(&quot;Number of Film permits in NYC by Category&quot;) + theme(legend.position=&quot;none&quot;) + theme_classic() 2.2.3.12 Sometimes layer order matters Interesting, theme_classic() is misbehaving a little bit and incorrectly renders the axis labels and reintroduces the legend. It looks like we have some of our layers out of order, let’s re-order. I just moved theme_classic() to just underneath the geom_bar() line. Now everything get’s drawn properly. ggplot(counts, aes(x = Category, y = count_of_permits, color=Category, fill= Category )) + geom_bar(stat=&quot;identity&quot;) + theme_classic() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ylab(&quot;Number of Film Permits&quot;) + xlab(&quot;Category of film&quot;) + ggtitle(&quot;Number of Film permits in NYC by Category&quot;) + theme(legend.position=&quot;none&quot;) 2.2.3.13 Font-size Changing font-size is often something you want to do. ggplot2 can do this in different ways. I suggest using the base_size option inside theme_classic(). You set one number for the largest font size in the graph, and everything else gets scaled to fit with that that first number. It’s really convenient. Look for the inside of theme_classic() ggplot(counts, aes(x = Category, y = count_of_permits, color=Category, fill= Category )) + geom_bar(stat=&quot;identity&quot;) + theme_classic(base_size = 15) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ylab(&quot;Number of Film Permits&quot;) + xlab(&quot;Category of film&quot;) + ggtitle(&quot;Number of Film permits in NYC by Category&quot;) + theme(legend.position=&quot;none&quot;) or make things small… just to see what happens ggplot(counts, aes(x = Category, y = count_of_permits, color=Category, fill= Category )) + geom_bar(stat=&quot;identity&quot;) + theme_classic(base_size = 10) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ylab(&quot;Number of Film Permits&quot;) + xlab(&quot;Category of film&quot;) + ggtitle(&quot;Number of Film permits in NYC by Category&quot;) + theme(legend.position=&quot;none&quot;) 2.2.3.14 ggplot2 summary That’s enough of the ggplot2 basics for now. You will discover that many things are possible with ggplot2. It is amazing. We are going to get back to answering some questions about the data with graphs. But, now that we have built the code to make the graphs, all we need to do is copy-paste, and make a few small changes, and boom, we have our graph. 2.2.4 More questions about NYC films 2.2.4.1 What are the sub-categories of films? Notice the nyc_films data frame also has a column for SubCategoryName. Let’s see what’s going on there with a quick plot. # comments are really useful: R will ignore them, but they can explain to a reader # what is going on in the code # get the counts counts &lt;- nyc_films %&gt;% group_by(SubCategoryName) %&gt;% # group by SubCategoryName instead of Borough/Category summarize(count_of_permits = length(SubCategoryName)) # make the plot ggplot(counts, aes(x = SubCategoryName, y = count_of_permits, color=SubCategoryName, fill= SubCategoryName )) + geom_bar(stat=&quot;identity&quot;) + theme_classic(base_size = 10) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ylab(&quot;Number of Film Permits&quot;) + xlab(&quot;Sub-category of film&quot;) + ggtitle(&quot;Number of Film permits in NYC by Sub-category&quot;) + theme(legend.position=&quot;none&quot;) I guess “episodic series” are the most common. Using a graph like this gave us our answer super fast. 2.2.4.2 Categories by different Boroughs Let’s see one more really useful thing about ggplot2. It’s called facet_wrap(). It’s an ugly word, but you will see that it is very cool, and you can do next-level-super-hero graph styles with facet_wrap that other people can’t do very easily. Here’s our question. We know that films are made in different Boroughs, and that films are made in different Categories, but do different Boroughs have different patterns for the kinds of categories of films they request permits for? Are their more TV shows in Brooklyn? How do we find out? Watch, just like this: # get the counts counts &lt;- nyc_films %&gt;% group_by(Borough,Category) %&gt;% # group by two categories: Borough and Category summarize(count_of_permits = length(Category)) # make the plot ggplot(counts, aes(x = Category, y = count_of_permits, color=Category, fill= Category )) + geom_bar(stat=&quot;identity&quot;) + theme_classic(base_size = 10) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ylab(&quot;Number of Film Permits&quot;) + xlab(&quot;Category of film&quot;) + ggtitle(&quot;Number of Film permits in NYC by Category and Borough&quot;) + theme(legend.position=&quot;none&quot;) + facet_wrap(~Borough, ncol=3) We did two important things. First we added Borough and Category into the group_by() function. This automatically gives separate counts for each category of film, for each Borough. Then we added facet_wrap(~Borough, ncol=3) to the end of the plot, and it automatically drew us 5 different bar graphs, one for each Borough! That was fast. Imagine doing that by hand. The nice thing about this is we can switch things around if we want. For example, we could do it this way by switching the Category with Borough, and facet-wrapping by Category instead of Borough like we did above. Do what works for you. ggplot(counts, aes(x = Borough, y = count_of_permits, color=Borough, fill= Borough )) + geom_bar(stat=&quot;identity&quot;) + theme_classic(base_size = 10) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ylab(&quot;Number of Film Permits&quot;) + xlab(&quot;Borough&quot;) + ggtitle(&quot;Number of Film permits in NYC by Category and Borough&quot;) + theme(legend.position=&quot;none&quot;) + facet_wrap(~Category, ncol=5) 2.2.5 Questions about the Gapminder dataset Gapminder is an organization that collects some really interesting worldwide data. They also make cool visualization tools for looking at the data. There are many neat examples, and they have visualization tools built right into their website that you can play around with: https://www.gapminder.org/tools/. That’s fun to check out. There is also an R package called gapminder. When you install this package, it loads in some of the data from gapminder, so we can play with it in R. If you don’t have the gapminder package installed, you can install it by running this code install.packages(&quot;gapminder&quot;) Once the package is installed, you need to load the new library and put the gapminder data into a data frame, like we do here: library(gapminder) gapminder_df &lt;- gapminder 2.2.5.1 Look at the data frame You can look at the data frame in the environment tab to see what is in it, and/or you can use the head()/tail()/summary()/str() and nrow/ncol functions again: head(gapminder_df) ## # A tibble: 6 x 6 ## country continent year lifeExp pop gdpPercap ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Afghanistan Asia 1952 28.8 8425333 779. ## 2 Afghanistan Asia 1957 30.3 9240934 821. ## 3 Afghanistan Asia 1962 32.0 10267083 853. ## 4 Afghanistan Asia 1967 34.0 11537966 836. ## 5 Afghanistan Asia 1972 36.1 13079460 740. ## 6 Afghanistan Asia 1977 38.4 14880372 786. tail(gapminder_df) ## # A tibble: 6 x 6 ## country continent year lifeExp pop gdpPercap ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Zimbabwe Africa 1982 60.4 7636524 789. ## 2 Zimbabwe Africa 1987 62.4 9216418 706. ## 3 Zimbabwe Africa 1992 60.4 10704340 693. ## 4 Zimbabwe Africa 1997 46.8 11404948 792. ## 5 Zimbabwe Africa 2002 40.0 11926563 672. ## 6 Zimbabwe Africa 2007 43.5 12311143 470. summary(gapminder_df) ## country continent year lifeExp ## Afghanistan: 12 Africa :624 Min. :1952 Min. :23.60 ## Albania : 12 Americas:300 1st Qu.:1966 1st Qu.:48.20 ## Algeria : 12 Asia :396 Median :1980 Median :60.71 ## Angola : 12 Europe :360 Mean :1980 Mean :59.47 ## Argentina : 12 Oceania : 24 3rd Qu.:1993 3rd Qu.:70.85 ## Australia : 12 Max. :2007 Max. :82.60 ## (Other) :1632 ## pop gdpPercap ## Min. :6.001e+04 Min. : 241.2 ## 1st Qu.:2.794e+06 1st Qu.: 1202.1 ## Median :7.024e+06 Median : 3531.8 ## Mean :2.960e+07 Mean : 7215.3 ## 3rd Qu.:1.959e+07 3rd Qu.: 9325.5 ## Max. :1.319e+09 Max. :113523.1 ## str(gapminder_df) ## tibble [1,704 × 6] (S3: tbl_df/tbl/data.frame) ## $ country : Factor w/ 142 levels &quot;Afghanistan&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ continent: Factor w/ 5 levels &quot;Africa&quot;,&quot;Americas&quot;,..: 3 3 3 3 3 3 3 3 3 3 ... ## $ year : int [1:1704] 1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ... ## $ lifeExp : num [1:1704] 28.8 30.3 32 34 36.1 ... ## $ pop : int [1:1704] 8425333 9240934 10267083 11537966 13079460 14880372 12881816 13867957 16317921 22227415 ... ## $ gdpPercap: num [1:1704] 779 821 853 836 740 ... nrow(gapminder_df) ## [1] 1704 ncol(gapminder_df) ## [1] 6 There are 1704 rows of data, and we see 6 columns: country, continent, year, life expectancy, population, and GDP per capita. We will show you how to graph some the data to answer a few different kinds of questions. Then you will form your own questions, and see if you can answer them with ggplot2 yourself. All you will need to do is copy and paste the following examples, and change them up a little bit. 2.2.5.2 Life expectancy histogram How long are people living all around the world according to this data set? There are many ways we could plot the data to find out. The first way is a histogram. We have many numbers for life expectancy in the column lifeExp. This is a big sample, full of numbers for 142 countries across many years. It’s easy to make a histogram in ggplot to view the distribution: ggplot(gapminder_df, aes(x=lifeExp))+ geom_histogram(color=&quot;white&quot;) See, that was easy. Next, is a code block that adds more layers and settings if you wanted to modify parts of the graph: ggplot(gapminder_df, aes(x = lifeExp)) + geom_histogram(color=&quot;white&quot;)+ theme_classic(base_size = 15) + ylab(&quot;Frequency count&quot;) + xlab(&quot;Life Expectancy&quot;) + ggtitle(&quot;Histogram of Life Expectancy from Gapminder&quot;) The histogram shows a wide range of life expectancies, from below 40 to just over 80. Histograms are useful, they can show you what kinds of values happen more often than others. One final thing about histograms in ggplot. You may want to change the bin size. That controls how wide or narrow, or the number of bars (how they split across the range), in the histogram. You need to set the bins= option in geom_histogram(). ggplot(gapminder_df, aes(x = lifeExp)) + geom_histogram(color=&quot;white&quot;, bins=50)+ theme_classic(base_size = 15) + ylab(&quot;Frequency count&quot;) + xlab(&quot;Life Expectancy&quot;) + ggtitle(&quot;Histogram of Life Expectancy from Gapminder&quot;) Same basic pattern, but now breaking up the range into 50 little equal sized bins, rather than 30, which is the default. You get to choose what you want to do. 2.2.5.3 Life expectancy time series plot We can see we have data for life expectancy and different years. So, does worldwide life expectancy change across the years in the data set? As we go into the future, are people living longer? Let’s look at this using something called a time series plot. We can set the x-axis to be year, and the y-axis to be life expectancy. Then we can use geom_point() to display a whole bunch of dots, and then look at them. Here’s the simple code: ggplot(gapminder_df, aes(y= lifeExp, x= year))+ geom_point() Whoa, that’s a lot of dots! Remember that each country is measured each year. So, the bands of dots you see, show the life expectancies for the whole range of countries within each year of the database. There is a big spread inside each year. But, on the whole it looks like groups of dots slowly go up over years. 2.2.5.4 One country, life expectancy by year I’m from The Netherlands, so maybe I want to know if life expectancy for Dutch people is going up over the years. To find out the answer for one country, we first need to split the full data set, into another smaller data set that only contains data for The Netherlands. In other words, we want only the rows where the word “Netherlands” is found in the country column. We will use the filter function from dplyr for this: # filter rows to contain Netherlands smaller_df &lt;- gapminder_df %&gt;% # use the &quot;is equal to&quot; operator to filter filter(country == &quot;Netherlands&quot;) # plot the new data contained in smaller_df ggplot(smaller_df, aes(y= lifeExp, x= year))+ geom_point() Note that to filter, we are using the == (is equal to) operator. I would say things are looking good for Dutch people, their life expectancy is going up over the years! 2.2.5.5 Multiple countries, one plot What if we want to look at a few countries together. We can do this too. We just change how we filter the data so more than one country is allowed, then we plot the data. We will also add some nicer color options and make the plot look pretty. First, the code: # filter rows to contain countries of choice # create a vector using c() with countries of choice countries_of_choice &lt;- c(&quot;Netherlands&quot;,&quot;France&quot;,&quot;Brazil&quot;) smaller_df &lt;- gapminder_df %&gt;% # use the %in% operator for filtering with vector filter(country %in% countries_of_choice) # plot the new data contained in smaller_df ggplot(smaller_df, aes(y= lifeExp, x= year, group= country))+ geom_point() The code above contains two new concepts: We create a vector of countries_of_choice using c() (combine). A vector is simply a variable that holds multiple values. We use the %in% operator to filter the column country by our vector countries_of_choice. We need to use the %in% operator when we filter with a vector (i.e filtering for multiple values) as opposed to the == (is equal to) operator we use when filtering for a single value. Looking at the plot, we can now see three sets of dots, but which are countries do they represent? Let’s add a legend, and make the graph better looking. ggplot(smaller_df,aes(y= lifeExp, x= year, group= country, color = country)) + geom_point()+ theme_classic(base_size = 15) + ylab(&quot;Life Expectancy&quot;) + xlab(&quot;Year&quot;) + ggtitle(&quot;Life expectancy by year for three countries&quot;) 2.2.5.6 geom_line() connecting the dots We might also want to connect the dots with a line, to make it easier to see the connection! Remember, ggplot2 draws layers on top of layers. So, we add in a new geom_line() layer. ggplot(smaller_df,aes(y= lifeExp, x= year, group= country, color = country)) + geom_point()+ geom_line()+ theme_classic(base_size = 15) + ylab(&quot;Life Expectancy&quot;) + xlab(&quot;Year&quot;) + ggtitle(&quot;Life expectancy by year for three countries&quot;) 2.2.6 Graphing exercises Use the code from above to solve the extra things we ask you to do for the following exercises: Make a histogram of GDP per capita. Make the plot as pretty or ugly as you want it to be. Make a time series plot of GDP per capita by year for the USA, Canada, and Mexico. Make sure to update the title and labels as well (hint: the USA is not named “USA” in the dataset). Make a time series plot of Life Expectancy by year for the five continents (hint: use the group_by() and summarise() functions). 2.3 Part two: describing data using numbers In the second part of this lab, we will describe our data and answer questions using numbers. In order to do this, we need some numbers first. 2.3.1 Playing with numbers As we’ve seen previously, we can put multiple numbers in a variable using the c() function: my_numbers &lt;- c(1,2,3,4) There a few handy ways to generate numbers. We can use seq() to make a sequence. Here it is making the numbers from 1 to 100 one_to_one_hundred &lt;- seq(1,100,1) We can repeat things, using rep. Here’s making 10 5s, and 25 1s: rep(10,5) ## [1] 10 10 10 10 10 rep(1,25) ## [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 all_together_now &lt;- c(rep(10,5),rep(1,25)) 2.3.1.1 Sum Let’s play with the numbers 1 to 100. First, let’s use the sum() function to add them up one_to_one_hundred &lt;- seq(1,100,1) sum(one_to_one_hundred) ## [1] 5050 2.3.1.2 Length We put 100 numbers into the variable one_to_one_hundred. We know how many numbers there are in there. How can we get R to tell us? We use length() for that. length(one_to_one_hundred) ## [1] 100 2.3.2 Central Tendency 2.3.2.1 Mean Remember the mean of some numbers is their sum, divided by the number of numbers. We can compute the mean like this: sum(one_to_one_hundred)/length(one_to_one_hundred) ## [1] 50.5 Or, we could just use the mean() function like this: mean(one_to_one_hundred) ## [1] 50.5 2.3.2.2 Median The median is the number in the exact middle of the numbers ordered from smallest to largest. If there are an even number of numbers (no number in the middle), then we take the number in between the two (decimal .5). Use the median function. There’s only 3 numbers here. The middle one is 2, that should be the median median(c(1,2,3)) ## [1] 2 2.3.2.3 Mode R does not a base function for the mode, which might surprise you. There’s a couple of reasons why, but we can workaround this omission. Firstly, you could install a library (like modeest) to import a function that can calculate the mode for you. Or you could write your own function. Below is an example of writing your own function, and then using it. Note I searched how to do this on Google, and am using the mode defined by this answer on stack overflow Remember, the mode is the most frequently occurring number in the set. # write a function to calculate the mode my_mode_function &lt;- function(x) { ux &lt;- unique(x) ux[which.max(tabulate(match(x, ux)))] } # apply to function to a vector of numbers my_mode_function(c(1,1,1,1,1,1,1,2,3,4)) ## [1] 1 Above 1 occurs the most, so the mode will be one. 2.3.3 Variation We often want to know how variable (i.e. different) the numbers in our data are. We are going to look at descriptive statistics to describe this such as the range, variance, the standard deviation, and a few others. First, let’s remind ourselves what variation looks like (it’s when the numbers are different). We will sample 100 numbers from a normal distribution (don’t worry about this yet), with a mean of 10, and a standard deviation of 5, and then make a histogram so we can see the variation around 10.. sample_numbers &lt;- rnorm(100,10,5) # instead of using ggplot, we can also use a simpler function go generate a histogram # this is easier than ggplot, but more limited in what we can do hist(sample_numbers) 2.3.3.1 Range The range is the minimum and maximum values in the set, we use the range function. range(sample_numbers) ## [1] -6.189654 23.465302 2.3.3.2 var() = variance We can find the sample variance using var(): var(sample_numbers) ## [1] 29.37067 Note: the above variance calculation divides by \\(n-1\\) instead of \\(n\\). We will learn in later weeks why this is often preferred. If you would like to divide by \\(n\\), you could write your own function based on the following code: x_bar &lt;- mean(sample_numbers) var_n &lt;- sum((sample_numbers - x_bar)^2)/length(sample_numbers) 2.3.3.3 sd() = standard deviation We find the sample standard deviation using sd(): sd(sample_numbers) ## [1] 5.419472 Remember that the standard deviation is just the square root of the variance, see: sqrt(var(sample_numbers)) ## [1] 5.419472 2.3.4 Descriptives by conditions Sometimes you will have a single variable with some numbers, and you can use the above functions to find the descriptives for that variable. Other times (most often in this course), you will have a big data frame of numbers, with different numbers in different conditions. You will want to find descriptive statistics for each the sets of numbers inside each of the conditions. Fortunately, this is where R really shines, it does it all for you in one go. Let’s illustrate the problem. Here I make a date frame with 10 numbers in each condition. There are 10 conditions, each labelled, A, B, C, D, E, F, G, H, I, J. scores &lt;- rnorm(100,10,5) conditions &lt;- rep(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;,&quot;F&quot;,&quot;G&quot;,&quot;H&quot;,&quot;I&quot;,&quot;J&quot;), each =10) my_df &lt;- data.frame(conditions,scores) If you look at the my_df data frame, you will see it has 100 rows, there are 10 rows for each condition with a label in the conditions column, and 10 scores for each condition in the scores column. What if you wanted to know the mean of the scores in each condition? You would want to find 10 means. 2.3.4.1 group_by() and summarise() We can easily do everything all at once using the group_by and summarise function from the dplyr package, as we’ve seen before: library(dplyr) my_df %&gt;% group_by(conditions) %&gt;% summarise(means = mean(scores)) ## # A tibble: 10 x 2 ## conditions means ## &lt;chr&gt; &lt;dbl&gt; ## 1 A 8.96 ## 2 B 10.3 ## 3 C 9.71 ## 4 D 11.2 ## 5 E 8.02 ## 6 F 9.89 ## 7 G 10.4 ## 8 H 10.3 ## 9 I 9.87 ## 10 J 6.70 The print out of this looks rather ugly. We can fix that by putting the results of our code into a new variable, then use knitr::kable() to print it out nicely when we knit the document. We can even caption the table by passing a caption argument. summary_df &lt;- my_df %&gt;% group_by(conditions) %&gt;% summarise(means = mean(scores)) knitr::kable(summary_df,caption = &quot;Means by condition.&quot;) Table 2.1: Means by condition. conditions means A 8.956183 B 10.325311 C 9.708113 D 11.228400 E 8.017857 F 9.886288 G 10.369518 H 10.296157 I 9.874129 J 6.695991 2.3.4.2 Multiple descriptives The best thing about the dplyr method, is that we can add more than one function, and we’ll get more than one summary returned, all in a nice format, let’s add the standard deviation: summary_df &lt;- my_df %&gt;% group_by(conditions) %&gt;% summarise(means = mean(scores), sds = sd(scores)) knitr::kable(summary_df) conditions means sds A 8.956183 3.431132 B 10.325311 6.135058 C 9.708113 7.752681 D 11.228400 4.081763 E 8.017857 5.057877 F 9.886288 5.847510 G 10.369518 5.374702 H 10.296157 3.877533 I 9.874129 6.461270 J 6.695991 6.378375 We’ll add the min and the max too: summary_df &lt;- my_df %&gt;% group_by(conditions) %&gt;% summarise(means = mean(scores), sds = sd(scores), min = min(scores), max = max(scores)) knitr::kable(summary_df) conditions means sds min max A 8.956183 3.431132 4.6111957 14.66423 B 10.325311 6.135058 0.5302826 19.58689 C 9.708113 7.752681 -2.0483369 23.63091 D 11.228400 4.081763 6.1483990 18.97898 E 8.017857 5.057877 -0.3081510 15.04178 F 9.886288 5.847510 1.1075222 17.88015 G 10.369518 5.374702 4.1994861 21.02590 H 10.296157 3.877533 2.7057666 15.63593 I 9.874129 6.461270 -0.2541210 18.02120 J 6.695991 6.378375 -3.4459113 17.25555 2.3.5 Describing gapminder Now that we know how to get descriptive statistics from R, we can do this with some real data. Let’s quickly ask a few questions about the gapminder data: library(gapminder) gapminder_df &lt;- gapminder 2.3.5.1 What are some descriptives for Life expectancy by continent? Copy the code from the last part of descriptives using dplyr, then change the names like this: summary_df &lt;- gapminder_df %&gt;% group_by(continent) %&gt;% summarise(means = mean(lifeExp), sds = sd(lifeExp), min = min(lifeExp), max = max(lifeExp)) knitr::kable(summary_df) continent means sds min max Africa 48.86533 9.150210 23.599 76.442 Americas 64.65874 9.345088 37.579 80.653 Asia 60.06490 11.864532 28.801 82.603 Europe 71.90369 5.433178 43.585 81.757 Oceania 74.32621 3.795611 69.120 81.235 2.3.6 Descriptive exercises What is the mean, standard deviation, minimum and maximum GDP per capita for all the gapminder data (across all the years and countries)? Print the values in a table with your own caption. What is the mean, median, variance, and length of the life expectancy variable for each continent in 2007? Print the values in a table with your own caption. Answer the following questions in your own words: Define the mode. Explain what would need to happen in order for a set of numbers to have two modes Define the median Define the mean Define the range When calculating the variance, explain what the difference scores represent Explain why the difference scores are squared when calculating the variance If one set of numbers had a standard deviation of 5, and another had a standard deviation of 10, which set of numbers would have greater variance? Explain why. When you have completed all exercises and are happy with your progress today, please knit your document and submit it to Canvas. If you finish before the time is up, you can help out your fellow students, start with the required readings of Week 3, or work on your assignment. If you haven’t done so already, make sure you’ve signed up for an assignment group. "],["week-3-correlation-and-causation.html", " 3 Week 3: Correlation and Causation 3.1 Learning goals 3.2 Part one: establishing causal relationships 3.3 Part two: correlations in R", " 3 Week 3: Correlation and Causation In lecture and in the textbook, we have been discussing the idea of correlation. This is the idea that two things that we measure can be somehow related to one another. For example, your personal happiness, which we could try to measure say with a questionnaire, might be related to other things in your life that we could also measure, such as number of close friends, yearly salary, how much chocolate you have in your bedroom, or how many times you have said the word Nintendo in your life. Some of the relationships that we can measure are meaningful, and might reflect a causal relationship where one thing causes a change in another thing. Some of the relationships are spurious, and do not reflect a causal relationship. In this lab we will discuss several concepts related to establishing causal relationship. You will also learn how to compute correlations between two variables and answer some questions about relationships between variables. To get started, download the lab template here (right click: save as) or from Canvas. Copy the lab template to your lab folder and open Lab.proj. 3.1 Learning goals During this lab you will do the following: Discuss relationships between variables and how to establish causal relationships Discuss the possible meaning of correlations that you observe Learn how to compute and visualize Pearson’s \\(r\\) between two variables in R 3.2 Part one: establishing causal relationships 3.2.1 Question 1 Take a close look at the following two examples. Each example consists of a graph showing the fluctuation of two variables and a statement suggesting how to interpret such evidence. Are these statements correct? Explain your answer. 3.2.1.1 Example 1 There is a positive causal relationship between the number of people who drowned by falling into a pool and the number of films Nicolas Cage appeared in. Figure 3.1: Relationship between number of drownings and films Nicolage Cage appeared in. Illustration by Tyler Vigen. 3.2.1.2 Example 2 There is a positive causal relationship between per capita consumption of mozzarella cheese and civil engineering doctorates awarded. Figure 3.2: Relationship between mozerella consumption and civil engineering doctorates. Illustration by Tyler Vigen. 3.2.2 Question 2 For both scenarios described below, identify a possible confounder (variable Z) and describe its association with variables X and Y. The observation that when ice cream sales go up drownings of people in swimming pools increase, led the researcher to believe that ice cream consumption increases drownings. The observation that there is a very strong correlation between the use of social media and symptoms of depression, led the researcher to believe that excessive use of social media causes symptoms of depression. 3.2.3 Question 3 The case below presents an empirical observation that leads to a proposition. First, you are asked to identify the problem with this proposition. Then, you must provide a solution to overcome this issue. Your proposed solution should strengthen claims of a causal relationship between variables X and Y. Your proposed solution should satisfy the following: Clearly identify the source of variation in the independent variable (i.e. define groups) Indicate how you would use the variation in the independent variable to test against the proposed causal relationship There is enough variation in the independent variable (i.e. number of groups) such that the effect of interest can be identified in sufficient detail. Case Observation: We observe that people who exercise their hobbies regularly tend to be happier. Proposition: The more one exercises his or her hobbies, the happier he or she will be. Problem: Solution: 3.2.4 Question 4 In the case from the previous question: how would you test the empirical validity of competing explanations? For example, how could you make test that exercising a hobby has a stronger effect for non-retires than it has for retires? Hint: In a table list the groups of one variable in rows and the groups of the other variable in columns. Then, each cell is a subgroup: a combination of two groups. The outcome variable is measured for each one of these subgroups. What should be the relationship between pairs of subgroups for the above statement to be true? 3.2.5 Question 5 In the previous question, you provided solutions to ambiguously formulated claims of causal relationships, in order to strengthen their empirical validity and to be able to draw meaningful conclusions. However, meaningful conclusions should be obtained from meaningful comparisons. According to the textbook, what does a meaningful comparison entail? 3.2.6 Question 6 According to the textbook, how can we obtain meaningful comparisons? 3.2.7 Question 7 The textbook discusses three different types of interventions (independent variables). Briefly describe what they are and provide an example of your own. 3.2.8 Question 8 Read the following two cases and decide whether or not the described experiment is internally valid. If not, identify the threat to internal validity by choosing from the options below. Selection bias Demand characteristics effect History effect Maturation effect Repeated testing effect Regression to the mean Differential attrition Non-response bias Experimenter bias Placebo effect 3.2.8.1 Case 1 It was the start of a new swim season, and the coach was already concerned about her swimmers’ lack of effort during the 20-minute dry-land portion of practice. She felt they didn’t take it seriously enough, and too often they would be talking or slacking off rather than doing the required stretches and exercises. She consulted with a sports psychologist. He suggested that she write the names of all 20 swimmers on individual slips of paper, scramble them, and then pick ten without looking. This would be used to assign swimmers to a Non-contingent Group (the first ten), who would have trainings on Monday, Wednesday and Friday, and a Contingent Group (the remainder), who would have training on Tuesday, Thursday, and Saturday. The coach thought it would be easier simply to assign the swimmers to groups on the basis of friendship, but she changed her mind after the psychologist explained the rationale for this slightly more cumbersome procedure. The intervention was that swimmers in the Contingent Group were told that if their dry-land productivity as a group for the day was 15% better than their average in the previous week then music would be played at the following practice. The productivity of the Non-contingent Group had no bearing on the playing of music. Then, each practice day for one week, observers unobtrusively recorded the swimmers’ productive behaviors during the dry-land training portion and calculated the percentage of one-minute intervals in which all swimmers in a group were being productive. Following this intervention, the dry-land productivity of the Contingent group was found to be higher than that of the Non-Contingent group so we can conclude that making the playing of music contingent on the swimmers’ dry-land productivity resulted in an increase in that productivity. 3.2.8.2 Case 2 Psychoanalysts at two different hospitals were asked to judge the well-being of a young man being interviewed on videotape. By the flip of a coin, psychoanalysts at a publicly-funded hospital were assigned to the Normal Group and psychoanalysts at a privately-funded hospital were assigned to the Abnormal Group. In the Normal Group, the doctors were told that the young man was a job applicant; in the Abnormal Group, the doctors were told that he was a patient. The mean adjustment rating by psychoanalysts in the Normal Group was 7 out of 8 compared to a 3.5 out of 8 rating by doctors in the Abnormal Group. We can conclude that the psychoanalysts’ ratings were affected by the label used to describe the young man. 3.3 Part two: correlations in R In this part of the lab we will use R to explore correlations between two variables. 3.3.1 cor() for correlation R has the cor function for computing Pearson’s \\(r\\) between any two variables. In fact this same function computes other versions of correlation, but we’ll skip those here. To use the function you just need two variables with numbers in them like this: x &lt;- c(1,3,2,5,4,6,5,8,9) y &lt;- c(6,5,8,7,9,7,8,10,13) cor(x,y) ## [1] 0.76539 Well, that was easy. 3.3.1.1 Scatterplots Let’s take our toy example, and plot the data in a scatterplot using ggplot2. Let’s also return the correlation and print it on the scatter plot. Remember, ggplot2 wants the data in a data.frame, so we first put our x and y variables in a data frame. library(ggplot2) df &lt;- data.frame(x,y) ggplot(df, aes(x=x,y=y))+ geom_point()+ geom_text(aes(label = round(cor(x,y), digits=2), x=2, y=12)) Wow, we’re moving fast here. Dissect the code above and see if you understand each step. 3.3.1.2 Lots of scatterplots Before we move on to real data, let’s generate some fake data first. Often we will have many measures of X and Y, split between a few different conditions, for example, A, B, C, and D. Let’s make some fake data for X and Y, for each condition A, B, C, and D, and then use facet_wrap() to look at four scatter plots all at once: x&lt;-rnorm(40,0,1) # rnorm() generates a normally distributed random variable y&lt;-rnorm(40,0,1) # You can always use ? to see what a function does. conditions&lt;-rep(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;), each=10) df_all &lt;- data.frame(conditions, x, y) ggplot(df_all, aes(x=x,y=y))+ geom_point()+ facet_wrap(~conditions) Figure 3.3: Facet wrapped scatterplots 3.3.1.3 Computing the correlations all at once We’ve seen how we can make four graphs at once. facet_wrap() will always try to make as many graphs as there are individual conditions in the column variable. In this case there are four, so it makes four. What we will do now is make a table of the correlations in addition to the scatter plot. We use functions from the dplyr library to calculate the correlations and the function kable() from the knitr library to output the table: library(dplyr) df_cor &lt;- df_all %&gt;% group_by(conditions) %&gt;% summarise(correlation = cor(x, y)) knitr::kable(df_cor,caption = &quot;Correlation by condition.&quot;) Table 3.1: Correlation by condition. conditions correlation A 0.3835259 B 0.0691988 C 0.0471978 D 0.4876181 OK, we are basically ready to turn to some real data and ask if there are correlations between interesting variables… but first some exercises. 3.3.2 Correlation exercises Calculate the correlation between the following two variables: x &lt;- c(1,2,4,8,16,32,64,NA,256,512) y &lt;- c(1,2,2,2,5,6,5,8,7,4) What happens in exercise 1? What is NA? What can you do to still calculate the correlation between x and y? The following plot has (at least) two visual problems: the value of the correlation is printed at every point and the correlation has an unnecessary amount of digits. Try to fix the problems in the code below. x &lt;- c(1,2,4,8,16,32,64,128,256,512) y &lt;- c(1,2,2,2,5,6,5,8,7,4) corxy &lt;- cor(x,y) df &lt;- data.frame(x,y) ggplot(df, aes(x=x,y=y))+ geom_point()+ geom_text(aes(label = corxy)) Looking at the plot above, why is it probably not valid to summarise this data using Pearson’s \\(r\\)? Notice, the facet_wrapped scatterplots (Figure 3.3) didn’t show the correlation (\\(r\\)) values. Printing these numbers on the plot is possible, but you have to use the df_cor data frame in geom_text(). Try to fix this in the code below. If you are unsure how to do this, you can always use ?geom_text() or try to Google the solution (keywords: geom_text(), label, data.frame). x&lt;-rnorm(40,0,1) y&lt;-rnorm(40,0,1) conditions&lt;-rep(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;), each=10) df_all &lt;- data.frame(conditions, x, y) df_cor &lt;- df_all %&gt;% group_by(conditions) %&gt;% summarise(correlation = cor(x, y)) ggplot(df_all, aes(x=x,y=y))+ geom_point()+ facet_wrap(~conditions) 3.3.3 Real data Let’s take a look at some correlations in real data. We are going to look at responses to a questionnaire about happiness that was sent around the world, from the World Happiness Report. 3.3.3.1 Load the data We first load the data into a data.frame. The following assumes that you have downloaded the zip file with the labs template which contains the data file in the data folder. library(data.table) whr_data &lt;- fread(&#39;data/WHR2018.csv&#39;) 3.3.3.2 Look at the data head(whr_data) tail(whr_data) summary(whr_data) str(whr_data) nrow(whr_data) ncol(whr_data) You should be able to see that there is data for many different countries, across a few different years. There are lots of different kinds of measures, and each are given a name. You can find in the report what each of the measures represent. For now, I’ll show you some examples of asking questions about relationships between variables within this data, then you get to ask and answer your own question. 3.3.3.3 Example question #1 For the year 2017, does a countries measure for “Social support” correlate with that countries measure for “Healthy life expectancy at birth?” Let’s find out. We calculate the correlation, and then we make the scatter plot. We did something similar in the textbook, so the following should look familiar to you: cor(whr_data$`Social support`, whr_data$`Healthy life expectancy at birth`) ## [1] NA ggplot(whr_data, aes(x=`Social support`, y=`Healthy life expectancy at birth`))+ geom_point()+ theme_classic() We see a lot of dots on the scatterplot, but the correlation has a value of NA (meaning undefined or not available). This occurred because there are some missing data points in the data and we can’t calculate a correlation over missing data. We should remove all the rows with missing data first, then calculate the correlation. We do this in a couple of steps. First, we create our own data.frame with only the numbers we want to analyse. Then we can select the columns we want to keep using select and use filter to remove the rows with NAs. library(dplyr) smaller_df &lt;- whr_data %&gt;% select(country, `Social support`, `Healthy life expectancy at birth`) %&gt;% filter(!is.na(`Social support`), !is.na(`Healthy life expectancy at birth`)) cor(smaller_df$`Social support`, smaller_df$`Healthy life expectancy at birth`) ## [1] 0.5867593 Now we see the correlation is approximately 0.59. However, this is the correlation for all years in the dataset, not just 2017. So, we need to filter for the year 2017 as well: library(dplyr) smaller_df &lt;- whr_data %&gt;% select(country, `Social support`, `Healthy life expectancy at birth`, `year`) %&gt;% filter(`year` == 2017) %&gt;% filter(!is.na(`Social support`), !is.na(`Healthy life expectancy at birth`)) cor(smaller_df$`Social support`, smaller_df$`Healthy life expectancy at birth`) ## [1] 0.7200551 ggplot(smaller_df, aes(x=`Social support`, y=`Healthy life expectancy at birth`))+ geom_point()+ theme_classic() Although the scatter plot shows the dots are everywhere, it generally shows as social support increases, life expectancy increases. Let’s add a best fit line, so the trend is more clear. We use the geom_smooth() function to do this. We can also change the alpha value of the dots so they blend it bit, and you can see more of them. # select DVs and filter for NAs and year == 2017 smaller_df &lt;- whr_data %&gt;% select(country, `Social support`, `Healthy life expectancy at birth`, `year`) %&gt;% filter(`year` == 2017) %&gt;% filter(!is.na(`Social support`), !is.na(`Healthy life expectancy at birth`)) # calculate correlation cor(smaller_df$`Social support`, smaller_df$`Healthy life expectancy at birth`) ## [1] 0.7200551 # plot the data with best fit line ggplot(smaller_df, aes(x=`Social support`, y=`Healthy life expectancy at birth`))+ geom_point(alpha=.5)+ geom_smooth(method=lm,se=FALSE)+ theme_classic() 3.3.3.4 Example question #2 After all that work, we can now speedily answer more questions. For example, what is the relationship between positive affect in a country and negative affect in a country? I wouldn’t be surprised if there was a negative correlation here: when positive feelings generally go up, shouldn’t negative feelings generally go down? To answer this question, we just copy paste the last code block, and change the DVs to be Positive affect, and Negative affect # select DVs and filter for NAs and year == 2017 smaller_df &lt;- whr_data %&gt;% select(country, `Positive affect`, `Negative affect`, `year`) %&gt;% filter(`year` == 2017) %&gt;% filter(!is.na(`Positive affect`), !is.na(`Negative affect`)) # calculate correlation cor(smaller_df$`Positive affect`, smaller_df$`Negative affect`) ## [1] -0.421422 # plot the data with best fit line ggplot(smaller_df, aes(x=`Positive affect`, y=`Negative affect`))+ geom_point(alpha=.5)+ geom_smooth(method=lm, se=FALSE)+ theme_classic() There we have it. As positive affect goes up, negative affect goes down. A negative correlation. 3.3.4 Theory exercises Answer the following questions in your own words: Explain the difference between a correlation of r = .3 and r = .7. What does a larger value of r represent? Explain the difference between a correlation of r = .5, and r = -.5. 3.3.5 Data exercise Now answer your own question about a relationship in the WHR dataset. This should be a different relationship (and about a different year) than the examples above. You should calculate Pearson’s \\(r\\) of this relationship, generate a scatterplot with a best fit line, print the correlation on the scatterplot, and print the mean and standard deviation of both variables in a table. Your code should include all steps, from loading the relevant libraries and data file, to generating all the required output. Use comments throughout your code to explain what your are doing. When you have completed all exercises and are happy with your progress today, please knit your document and submit it to Canvas. If you finish before the time is up, start with the required readings of Week 4, work on your assignment, or help out your fellow students. "],["week-4-chance-and-probability-theory.html", " 4 Week 4: Chance and Probability Theory 4.1 Learning goals 4.2 Part one: correlation and random chance 4.3 Part two: generating data in R", " 4 Week 4: Chance and Probability Theory This week we learned that we can find correlations by chance alone, even when there is no true correlation between the variables. During the first part of this lab we are going to explore this phenomenon further. We will generate some random data and then look at the correlations we calculate. This will serve to develop our intuitions about inferential statistics; the focus of the remainder of this course. In the second part of the lab we are going to dive deeper in generating simulated data, which is very useful in helping us understand real data, and calculate all sorts of things about probability distributions. To get started, download the lab template here (right click: save as) or from Canvas. Copy the lab template to your lab folder and open Lab.proj. 4.1 Learning goals During this lab you will do the following: Explore correlations and random chance Learn how to generate simulated data in R Calculate and work with z-scores in R 4.2 Part one: correlation and random chance We saw in the textbook, that we can find correlations by chance alone, even when there is no true correlation between the variables. For example, suppose we randomly sampled some whole numbers into x and y. We know they shouldn’t be related, because we randomly sampled the numbers. However, chance alone will sometimes create correlations between x and y. You can demonstrate this to yourself by using the code below. Let’s look at 20 “experiments,” with 5 random numbers for x and y each. library(ggplot2) x&lt;-round(runif(5*20,1,10)) # runif() draws a random sample from a uniform distribution y&lt;-round(runif(5*20,1,10)) conditions&lt;-rep(1:20, each=5) all_df &lt;- data.frame(conditions, x, y) ggplot(all_df, aes(x=x,y=y))+ geom_point()+ geom_smooth(method=lm, se=FALSE)+ facet_wrap(~conditions)+ theme_classic() You can see that the slope of the blue line is not always flat. Sometimes it looks like there is a correlation, when we know there shouldn’t be. You can keep re-doing this graph, by re-knitting your RMarkdown document, or by pressing the little green play button. This is basically you simulating the experiments as many times as you press the button. 4.2.1 Chance exercises There are three questions to answer for this exercise. For the first two questions, you will be sampling random numbers from a uniform distribution a 1000 times. The first two questions are: Estimate the range (minimum and maximum) of correlations that could occur by chance between two variables with n = 10. Estimate the range (minimum and maximum) of correlations that could occur by chance between two variables with n = 25. Hint: to estimate the range of correlations that chance can produce we could to randomly sample x and y many times (like in the first example), save the correlation between x and y each time, then look at the smallest and largest correlation. How can you do this programmatically, without having to press the ‘play’ button hundreds of times? The answer is using a for loop. The code below shows how to repeat everything inside the for loop 5 times. The variable i is an index, that goes from 1 to 5. The saved_value variable starts out as an empty variable, and then we put a value into it (at index position i, from 1 to 5). In this code, we put the sum of the products of x and y into the saved_value variable. At the end of the simulation, the save_value variable contains 5 numbers. The min() and max() functions are used to find the minimum and maximum values for each of the 5 simulations. You should be able to modify this code to answer question 1 and 2. saved_value &lt;- c() #make an empty variable for (i in 1:5) { x &lt;- runif(n=10, min=1, max=10) y &lt;- runif(n=10, min=1, max=10) saved_value[i] &lt;- sum(x*y) } min(saved_value) ## [1] 203.2123 max(saved_value) ## [1] 415.8501 The third question is as follows: What proportion of correlations (from question 1 and 2) is smaller than -0.3 and larger than +0.3 for n = 10 and n = 25? Create a histogram of the correlations for n = 10 and n = 25 and draw a vertical line at -0.3 and +0.3. Print the found proportions on the plots. Use ggarrange() from the ggpubr library to plot the histograms alongside each other in one figure. Generating the correct histograms for this question is probably harder than you expect. Remember, programming is an iterative process, you almost never get to the solution in the first go and there are multiple ways to get to the solution. Make liberal use of the help function in R, Google, or ask help from your classmates / the tutor when stuck. 4.3 Part two: generating data in R There are many ways to make R generate numbers for you. We already looked at using a uniform distribution to generate numbers for our random correlations. In this next part, we will explore additional functions and distributions to generate random numbers. 4.3.1 sample() The sample function is like an endless gumball machine. You put the gumballs inside with different properties, say As and Bs, and then you let sample endlessly take gumballs out. Check it out: gumballs &lt;- c(&quot;A&quot;,&quot;B&quot;) sample_of_gumballs &lt;-sample(gumballs, 10, replace=TRUE) sample_of_gumballs ## [1] &quot;B&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; Here the sample function randomly picks A or B each time. We set it do this 10 times, so our sample has 10 things in it. We set replace=TRUE so that after each sample, we put the item back into the gumball machine and start again. Here’s another example with numbers: some_numbers &lt;- c(1,2,3,4,5,5,5,5) sample_of_numbers &lt;-sample(some_numbers, 20, replace=TRUE) sample_of_numbers ## [1] 3 5 5 5 5 5 2 5 5 5 4 1 5 1 2 5 2 5 2 4 Let’s do one more thing with sample. Let’s sample 1000 times from our some_numbers variable, and then look at the histogram some_numbers &lt;- c(1,2,3,4,5,5,5,5) sample_of_numbers &lt;-sample(some_numbers, 1000, replace=TRUE) hist(sample_of_numbers) # we are using the built in hist() function. we could also use ggplot to generate this histogram: ggplot(data.frame(sample_of_numbers),aes(x=sample_of_numbers)) + geom_histogram() We are looking at lots of samples from our little gumball machine of numbers. Notice that as we put more 5s in, more 5s come out of in our big sample of 1000. 4.3.2 rbinom() You can think of the binomial distribution as a coin flipping distribution. Or dice roll distribution. Or anything you can define a number of “successes” for. For example, when flipping a coin, we could consider flipping heads a “success.” You use rbinom as follows: rbinom(n, size, prob). n gives the number of flips you want to make. size is the number of coins you want to flip at once. prob is the probability that defines how often a “success” happens. Here’s how we flip one coin 10 times using rbinom (assuming the coin is fair): coin_flips &lt;- rbinom(10,1,.5) coin_flips ## [1] 0 1 1 0 1 0 0 0 1 0 We get a bunch of 0s, and 1s. We can pretend 0 = tails, and 1 = heads. If you flip 10 coins, how many heads do you get? We can can do the above again, and then sum(coin_flips). coin_flips &lt;- rbinom(10,1,.5) sum(coin_flips) ## [1] 3 Alright, so we get the sum of the 1s (i.e. the successes), which tells us the number of heads. But, if you keep redoing the above, you’ll get different answers each time. 5 heads will be the most frequent answer, but you will get lots of other answers too. We could do this 1000 times over, saving the number of heads for each set of 10 flips. Then we could look at the distribution of those sums. That would tell us about the range of things that can happen when we flip a coin 10 times. We can do that in a for loop like this: save_number_of_heads&lt;-length(1000) # make an empty variable to save things in for(i in 1:1000){ save_number_of_heads[i] &lt;- sum(rbinom(10,1,.5)) } hist(save_number_of_heads) The histogram shows us the frequency observing different numbers of heads (for 10 flips) across the 1000 simulations. 5 happens the most, but 2 happens sometimes, and so does 8. All of the possibilities seem to happen sometimes, some more than others. 4.3.3 sample and binom() exercises Why are you unable to run the following bit of code? What could you do to fix this? Does this change the nature of your sampling procedure? sample(c(1:10), 20) How many sixes do you expect to roll when rolling 1 dice 10,000 times? And how many fives and sixes do you expect to roll when rolling 10 dice 10,000 times? What is the probability of obtaining exactly 4 heads when flipping 10 fair coins? And what is the probability to obtain at least 4 heads (so 4, 5, 6, 7, 8, 9 or 10 heads)? Cf. the textbook when unsure how to use the binom() functions. 4.3.4 rnorm() We’ll quickly show how to use rnorm(n, mean=0, sd=1) to sample numbers from a normal distribution. It’s similar to rbinom(), but now you are sampling from a normal distribution instead: hist(rnorm(10000,0,1)) There it is, a bell-shaped normal distribution with a mean of 0, and a standard deviation of 1. Just by changing the arguments of the rnorm() function, you can sample numbers from normal distributions with any mean or standard deviation. The nice thing about R functions is that they are a bit like Legos, you can put them together and come up with different things. What if wanted to sample from a distribution that looked like a two-humped camel’s back? Just sample from rnorm twice like this… mix away. hist( c( rnorm(100,25,5), rnorm(100,50,5)) ) You can generate as many numbers under a certain distribution as your computer can handle. 4.3.5 Graphing the normal distribution “Wait, I thought we already graphed a normal distribution.” We sort of did. We sampled numbers and made histograms that looked like a normal distribution. But, a normal distribution is more of an abstract idea. It looks like this in the abstract: normal_dist &lt;- dnorm(seq(-4,4,.1), 0, 1) values &lt;-seq(-4,4,.1) normal_df &lt;-data.frame(values,normal_dist) ggplot(normal_df, aes(x=values,y=normal_dist))+ geom_line()+ theme_classic() A really nice shaped bell-like thing. This normal distribution has a mean of 0, and standard deviation of 1. The heights of the lines tell you roughly how likely each value is. Notice, it is centered on 0 (most likely that numbers from this distribution will be near 0), and it goes down as numbers get bigger or smaller (so bigger or smaller numbers get less likely). Notice the values don’t go much beyond -4 and +4. This is because those values don’t happen very often. Theoretically any value could happen, but really big or small values have really low probabilities. 4.3.6 Calculating the probability of specific ranges. We can use R to tell us about the probability of getting numbers in a certain range. For example, when you think about it, it should be obvious that you have a 50% probability of getting the number 0 or lower. Half of the distribution is 0 or lower, so you have a 50% probability. We can use the pnorm() function to confirm this: pnorm(0, mean = 0, sd= 1) ## [1] 0.5 Agreed, pnorm() tells us the probability of getting 0 or lower is 0.5. Well, what is the probability of getting a 2 or greater? That’s a bit harder to judge, but obviously less than 50%. Use R like this to find out: pnorm(2, mean = 0, sd= 1) ## [1] 0.9772499 That doesn’t seem quite right. R is telling us the probability is 0.977, while we know it should be smaller than 0.5. That’s because by default, pnorm() gives the probability “up to and including” (denoted: P[X ≤ x]). The figure below visualizes what that means: So, to get the probability of getting a 2 or greater, we have to take \\(1 - 0.9772499 = 0.0227501\\): Or, we could use the lower.tail argument: pnorm(2, mean = 0, sd= 1,lower.tail = FALSE) ## [1] 0.02275013 So, the probability of getting a 2 or greater is .0227 (not very probable) 4.3.7 norm() exercises Run the following bit of code, which samples 20 random numbers from a normal distribution, a couple of times and look at the results. What do you think the function set.seed() does? When do you think this could be useful? set.seed(123) some_numbers &lt;- rnorm(20,50,25) # 20 numbers, mean = 50, s.d. = 25 print(some_numbers) ## [1] 35.9881088 44.2455628 88.9677079 51.7627098 53.2321934 92.8766247 ## [7] 61.5229051 18.3734691 32.8286787 38.8584507 80.6020449 58.9953457 ## [13] 60.0192863 52.7670679 36.1039716 94.6728284 62.4462620 0.8345711 ## [19] 67.5338975 38.1802148 Suppose the mean of a normal distribution is 25 (\\(\\mu = 25\\)) and the standard deviation is 3 (\\(\\sigma=3\\)). Calculate the probability of obtaining a value between 22 and 28 using R. Based on what you know about the standard normal distribution, could you have figured this out without calculations? Use R to calculate the probability of obtaining a value higher than 29.5 for this normal distribution. 4.3.8 z-scores We just spent a bunch of time looking at a very special normal distribution, the one where the mean = 0, and the standard deviation = 1. This special normal distribution is called the standard normal distribution. Often, we are not dealing with a normal distribution exactly like this. For example, someone might say, I got a number, it’s 545. It came from a normal distribution with mean = 600, and standard deviation = 25. So, does 545 happen a lot or not? The numbers don’t tell you right away. But if we were talking about the standard normal distribution with mean = 0 and standard deviation = 1, and I told I got a number -2.2 from that distribution, you would know directly that -2.2 doesn’t happen a lot. z-scores are a way of transforming one set of numbers into the standard normal distribution. To calculate z-scores we take the following steps: First get some numbers: some_numbers &lt;- rnorm(20,50,25) # 20 numbers, mean = 50, s.d. = 25 Calculate the mean and standard deviation: my_mean &lt;- mean(some_numbers) my_sd &lt;-sd(some_numbers) print(my_mean) ## [1] 48.71857 print(my_sd) ## [1] 20.74847 Subtract the mean from your numbers: differences&lt;-some_numbers-my_mean print(differences) ## [1] -25.4141636 -4.1679438 -24.3686822 -16.9408517 -14.3445527 -40.8859037 ## [7] 22.2261051 5.1157570 -27.1719944 32.6268021 11.9430346 -6.0953580 ## [13] 23.6595706 23.2347662 21.8209561 18.4974354 15.1293704 -0.2663637 ## [19] -6.3676376 -8.2303460 Divide each number by the standard deviation: z_scores&lt;-differences/my_sd print(z_scores) ## [1] -1.22486947 -0.20087961 -1.17448110 -0.81648691 -0.69135482 -1.97055060 ## [7] 1.07121675 0.24656072 -1.30959047 1.57249219 0.57561046 -0.29377390 ## [13] 1.14030452 1.11983051 1.05169005 0.89150854 0.72918016 -0.01283775 ## [19] -0.30689677 -0.39667249 Done. Now you have converted your original numbers into what we call standardized scores (or z-scores). They are standardized to have the same properties (assumed properties) as a normal distribution with mean = 0, and standard deviation = 1. 4.3.9 z-score exercises Right click and download this SPSS file containing 49 students’ exam grades (let’s say it’s the final exam for a statistics class). You have likely never worked with an SPSS (.sav) file before, but still, with a quick Google search, you should be able to find a library and function to load the data into R. Remember, you can install packages using install.packages() and load a library with library(). Make sure the .sav is in your working directory so you can load it into R. Once you have successfully loaded the data into R: Create a table containing the mean and standard deviation for this sample of scores. Also produce a frequency histogram of the grades. How does the distribution of grades look? Transform each student’s score into a Z-score. Now, plot the frequency histogram of this Z-score distribution. Compare it to the raw score distribution. How are they the same? How are they different? Imagine you are a student in this class who received a 90 on this exam. However, the Professor has decided to grade on a curve, such that only the top 10% of the class receives an A (this professor only gives whole grades, no minuses or pluses). Calculate the z-score that corresponds to a raw score of 90 on this exam. Will you get an A with this grade? Why or why not? When you have completed all exercises and are happy with your progress today, please knit your document and submit it to Canvas. If you finish before the time is up, start with the required readings of Week 5, work on your assignment, or help out your fellow students. "],["references.html", " 5 References", " 5 References R Core Team. 2020. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/. "]]
