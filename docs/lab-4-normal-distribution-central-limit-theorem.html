<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title> 5 Lab 4: Normal Distribution &amp; Central Limit Theorem | Lab manual QuantRMA</title>
  <meta name="description" content="The lab manual for quantitative research methods and data analysis at EUC. This text was adapted from “Answering questions with data: Lab Manual” by Matthew J.C. Crump and colleagues (https://crumplab.github.io/statistics/)" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content=" 5 Lab 4: Normal Distribution &amp; Central Limit Theorem | Lab manual QuantRMA" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The lab manual for quantitative research methods and data analysis at EUC. This text was adapted from “Answering questions with data: Lab Manual” by Matthew J.C. Crump and colleagues (https://crumplab.github.io/statistics/)" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content=" 5 Lab 4: Normal Distribution &amp; Central Limit Theorem | Lab manual QuantRMA" />
  
  <meta name="twitter:description" content="The lab manual for quantitative research methods and data analysis at EUC. This text was adapted from “Answering questions with data: Lab Manual” by Matthew J.C. Crump and colleagues (https://crumplab.github.io/statistics/)" />
  

<meta name="author" content="Original authors: Matthew J. C. Crump, Anjali Krishnan, Stephen Volz, and Alla Chavarga" />
<meta name="author" content="Adapted for EUC by Thomas Hulst and Thanos Kostopoulos" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="week-4-chance-and-probability-theory.html"/>
<link rel="next" href="references.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Lab manual QuantRMA</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#important-notes"><i class="fa fa-check"></i>Important notes</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#attributions"><i class="fa fa-check"></i>Attributions</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#cc-by-sa-4.0-license"><i class="fa fa-check"></i>CC BY-SA 4.0 license</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="getting-started-adapted1.html"><a href="getting-started-adapted1.html"><i class="fa fa-check"></i>Getting started</a><ul>
<li class="chapter" data-level="0.1" data-path="getting-started-adapted1.html"><a href="getting-started-adapted1.html#why-r"><i class="fa fa-check"></i><b>0.1</b> Why R?</a></li>
<li class="chapter" data-level="0.2" data-path="getting-started-adapted1.html"><a href="getting-started-adapted1.html#downloading-and-installing-r"><i class="fa fa-check"></i><b>0.2</b> Downloading and installing R</a><ul>
<li class="chapter" data-level="0.2.1" data-path="getting-started-adapted1.html"><a href="getting-started-adapted1.html#installing-r-on-a-mac"><i class="fa fa-check"></i><b>0.2.1</b> Installing R on a Mac</a></li>
<li class="chapter" data-level="0.2.2" data-path="getting-started-adapted1.html"><a href="getting-started-adapted1.html#installing-r-on-a-windows-pc"><i class="fa fa-check"></i><b>0.2.2</b> Installing R on a Windows PC</a></li>
<li class="chapter" data-level="0.2.3" data-path="getting-started-adapted1.html"><a href="getting-started-adapted1.html#installing-r-on-a-linux-pc"><i class="fa fa-check"></i><b>0.2.3</b> Installing R on a Linux PC</a></li>
</ul></li>
<li class="chapter" data-level="0.3" data-path="getting-started-adapted1.html"><a href="getting-started-adapted1.html#RStudio"><i class="fa fa-check"></i><b>0.3</b> Downloading and installing RStudio</a></li>
<li class="chapter" data-level="0.4" data-path="getting-started-adapted1.html"><a href="getting-started-adapted1.html#understanding-rstudio"><i class="fa fa-check"></i><b>0.4</b> Understanding RStudio</a><ul>
<li class="chapter" data-level="0.4.1" data-path="getting-started-adapted1.html"><a href="getting-started-adapted1.html#consoleR"><i class="fa fa-check"></i><b>0.4.1</b> Console</a></li>
<li class="chapter" data-level="0.4.2" data-path="getting-started-adapted1.html"><a href="getting-started-adapted1.html#script-editor"><i class="fa fa-check"></i><b>0.4.2</b> Script Editor</a></li>
<li class="chapter" data-level="0.4.3" data-path="getting-started-adapted1.html"><a href="getting-started-adapted1.html#workspace-and-history"><i class="fa fa-check"></i><b>0.4.3</b> Workspace and History</a></li>
<li class="chapter" data-level="0.4.4" data-path="getting-started-adapted1.html"><a href="getting-started-adapted1.html#fileplot"><i class="fa fa-check"></i><b>0.4.4</b> File, Plot, Packages, Help</a></li>
<li class="chapter" data-level="0.4.5" data-path="getting-started-adapted1.html"><a href="getting-started-adapted1.html#installing-libraries"><i class="fa fa-check"></i><b>0.4.5</b> Installing libraries</a></li>
</ul></li>
<li class="chapter" data-level="0.5" data-path="getting-started-adapted1.html"><a href="getting-started-adapted1.html#how-to-complete-the-labs"><i class="fa fa-check"></i><b>0.5</b> How to complete the labs</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="week-1-introductionadapted2.html"><a href="week-1-introductionadapted2.html"><i class="fa fa-check"></i><b>1</b> Week 1: Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="week-1-introductionadapted2.html"><a href="week-1-introductionadapted2.html#general-goals"><i class="fa fa-check"></i><b>1.1</b> General Goals</a></li>
<li class="chapter" data-level="1.2" data-path="week-1-introductionadapted2.html"><a href="week-1-introductionadapted2.html#part-one-research-methods"><i class="fa fa-check"></i><b>1.2</b> Part one: research methods</a><ul>
<li class="chapter" data-level="1.2.1" data-path="week-1-introductionadapted2.html"><a href="week-1-introductionadapted2.html#question-1"><i class="fa fa-check"></i><b>1.2.1</b> Question 1</a></li>
<li class="chapter" data-level="1.2.2" data-path="week-1-introductionadapted2.html"><a href="week-1-introductionadapted2.html#question-2"><i class="fa fa-check"></i><b>1.2.2</b> Question 2</a></li>
<li class="chapter" data-level="1.2.3" data-path="week-1-introductionadapted2.html"><a href="week-1-introductionadapted2.html#question-3"><i class="fa fa-check"></i><b>1.2.3</b> Question 3</a></li>
<li class="chapter" data-level="1.2.4" data-path="week-1-introductionadapted2.html"><a href="week-1-introductionadapted2.html#question-4"><i class="fa fa-check"></i><b>1.2.4</b> Question 4</a></li>
<li class="chapter" data-level="1.2.5" data-path="week-1-introductionadapted2.html"><a href="week-1-introductionadapted2.html#question-5"><i class="fa fa-check"></i><b>1.2.5</b> Question 5</a></li>
<li class="chapter" data-level="1.2.6" data-path="week-1-introductionadapted2.html"><a href="week-1-introductionadapted2.html#question-6"><i class="fa fa-check"></i><b>1.2.6</b> Question 6</a></li>
<li class="chapter" data-level="1.2.7" data-path="week-1-introductionadapted2.html"><a href="week-1-introductionadapted2.html#question-7"><i class="fa fa-check"></i><b>1.2.7</b> Question 7</a></li>
<li class="chapter" data-level="1.2.8" data-path="week-1-introductionadapted2.html"><a href="week-1-introductionadapted2.html#question-8"><i class="fa fa-check"></i><b>1.2.8</b> Question 8</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="week-1-introductionadapted2.html"><a href="week-1-introductionadapted2.html#part-two-introduction-to-r"><i class="fa fa-check"></i><b>1.3</b> Part two: introduction to R</a><ul>
<li class="chapter" data-level="1.3.1" data-path="week-1-introductionadapted2.html"><a href="week-1-introductionadapted2.html#arithmetic"><i class="fa fa-check"></i><b>1.3.1</b> Doing simple calculations with R</a></li>
<li class="chapter" data-level="1.3.2" data-path="week-1-introductionadapted2.html"><a href="week-1-introductionadapted2.html#usingfunctions"><i class="fa fa-check"></i><b>1.3.2</b> Using functions to do calculations</a></li>
<li class="chapter" data-level="1.3.3" data-path="week-1-introductionadapted2.html"><a href="week-1-introductionadapted2.html#assign"><i class="fa fa-check"></i><b>1.3.3</b> Storing a number as a variable</a></li>
<li class="chapter" data-level="1.3.4" data-path="week-1-introductionadapted2.html"><a href="week-1-introductionadapted2.html#using-comments"><i class="fa fa-check"></i><b>1.3.4</b> Using comments</a></li>
<li class="chapter" data-level="1.3.5" data-path="week-1-introductionadapted2.html"><a href="week-1-introductionadapted2.html#r-is-pretty-stupid"><i class="fa fa-check"></i><b>1.3.5</b> R is pretty stupid?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="week-2-describing-data.html"><a href="week-2-describing-data.html"><i class="fa fa-check"></i><b>2</b> Week 2: Describing Data</a><ul>
<li class="chapter" data-level="2.1" data-path="week-2-describing-data.html"><a href="week-2-describing-data.html#general-goals-1"><i class="fa fa-check"></i><b>2.1</b> General Goals</a></li>
<li class="chapter" data-level="2.2" data-path="week-2-describing-data.html"><a href="week-2-describing-data.html#part-one-describing-data-using-graphs"><i class="fa fa-check"></i><b>2.2</b> Part one: describing data using graphs</a><ul>
<li class="chapter" data-level="2.2.1" data-path="week-2-describing-data.html"><a href="week-2-describing-data.html#look-at-the-data"><i class="fa fa-check"></i><b>2.2.1</b> Look at the data</a></li>
<li class="chapter" data-level="2.2.2" data-path="week-2-describing-data.html"><a href="week-2-describing-data.html#data-exercises"><i class="fa fa-check"></i><b>2.2.2</b> Data exercises</a></li>
<li class="chapter" data-level="2.2.3" data-path="week-2-describing-data.html"><a href="week-2-describing-data.html#make-plots-to-answer-questions"><i class="fa fa-check"></i><b>2.2.3</b> Make plots to answer questions</a></li>
<li class="chapter" data-level="2.2.4" data-path="week-2-describing-data.html"><a href="week-2-describing-data.html#more-questions-about-nyc-films"><i class="fa fa-check"></i><b>2.2.4</b> More questions about NYC films</a></li>
<li class="chapter" data-level="2.2.5" data-path="week-2-describing-data.html"><a href="week-2-describing-data.html#questions-about-the-gapminder-dataset"><i class="fa fa-check"></i><b>2.2.5</b> Questions about the Gapminder dataset</a></li>
<li class="chapter" data-level="2.2.6" data-path="week-2-describing-data.html"><a href="week-2-describing-data.html#graphing-exercises"><i class="fa fa-check"></i><b>2.2.6</b> Graphing exercises</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="week-2-describing-data.html"><a href="week-2-describing-data.html#part-two-describing-data-using-numbers"><i class="fa fa-check"></i><b>2.3</b> Part two: describing data using numbers</a><ul>
<li class="chapter" data-level="2.3.1" data-path="week-2-describing-data.html"><a href="week-2-describing-data.html#playing-with-numbers"><i class="fa fa-check"></i><b>2.3.1</b> Playing with numbers</a></li>
<li class="chapter" data-level="2.3.2" data-path="week-2-describing-data.html"><a href="week-2-describing-data.html#central-tendency"><i class="fa fa-check"></i><b>2.3.2</b> Central Tendency</a></li>
<li class="chapter" data-level="2.3.3" data-path="week-2-describing-data.html"><a href="week-2-describing-data.html#variation"><i class="fa fa-check"></i><b>2.3.3</b> Variation</a></li>
<li class="chapter" data-level="2.3.4" data-path="week-2-describing-data.html"><a href="week-2-describing-data.html#descriptives-by-conditions"><i class="fa fa-check"></i><b>2.3.4</b> Descriptives by conditions</a></li>
<li class="chapter" data-level="2.3.5" data-path="week-2-describing-data.html"><a href="week-2-describing-data.html#describing-gapminder"><i class="fa fa-check"></i><b>2.3.5</b> Describing gapminder</a></li>
<li class="chapter" data-level="2.3.6" data-path="week-2-describing-data.html"><a href="week-2-describing-data.html#descriptive-exercises"><i class="fa fa-check"></i><b>2.3.6</b> Descriptive exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="week-3-correlation-and-causation.html"><a href="week-3-correlation-and-causation.html"><i class="fa fa-check"></i><b>3</b> Week 3: Correlation and Causation</a><ul>
<li class="chapter" data-level="3.1" data-path="week-3-correlation-and-causation.html"><a href="week-3-correlation-and-causation.html#general-goals-2"><i class="fa fa-check"></i><b>3.1</b> General Goals</a></li>
<li class="chapter" data-level="3.2" data-path="week-3-correlation-and-causation.html"><a href="week-3-correlation-and-causation.html#part-one-establishing-causal-relationships"><i class="fa fa-check"></i><b>3.2</b> Part one: establishing causal relationships</a><ul>
<li class="chapter" data-level="3.2.1" data-path="week-3-correlation-and-causation.html"><a href="week-3-correlation-and-causation.html#question-1-1"><i class="fa fa-check"></i><b>3.2.1</b> Question 1</a></li>
<li class="chapter" data-level="3.2.2" data-path="week-3-correlation-and-causation.html"><a href="week-3-correlation-and-causation.html#question-2-1"><i class="fa fa-check"></i><b>3.2.2</b> Question 2</a></li>
<li class="chapter" data-level="3.2.3" data-path="week-3-correlation-and-causation.html"><a href="week-3-correlation-and-causation.html#question-3-1"><i class="fa fa-check"></i><b>3.2.3</b> Question 3</a></li>
<li class="chapter" data-level="3.2.4" data-path="week-3-correlation-and-causation.html"><a href="week-3-correlation-and-causation.html#question-4-1"><i class="fa fa-check"></i><b>3.2.4</b> Question 4</a></li>
<li class="chapter" data-level="3.2.5" data-path="week-3-correlation-and-causation.html"><a href="week-3-correlation-and-causation.html#question-5-1"><i class="fa fa-check"></i><b>3.2.5</b> Question 5</a></li>
<li class="chapter" data-level="3.2.6" data-path="week-3-correlation-and-causation.html"><a href="week-3-correlation-and-causation.html#question-6-1"><i class="fa fa-check"></i><b>3.2.6</b> Question 6</a></li>
<li class="chapter" data-level="3.2.7" data-path="week-3-correlation-and-causation.html"><a href="week-3-correlation-and-causation.html#question-7-1"><i class="fa fa-check"></i><b>3.2.7</b> Question 7</a></li>
<li class="chapter" data-level="3.2.8" data-path="week-3-correlation-and-causation.html"><a href="week-3-correlation-and-causation.html#question-8-1"><i class="fa fa-check"></i><b>3.2.8</b> Question 8</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="week-3-correlation-and-causation.html"><a href="week-3-correlation-and-causation.html#part-two-correlations-in-r"><i class="fa fa-check"></i><b>3.3</b> Part two: correlations in R</a><ul>
<li class="chapter" data-level="3.3.1" data-path="week-3-correlation-and-causation.html"><a href="week-3-correlation-and-causation.html#cor-for-correlation"><i class="fa fa-check"></i><b>3.3.1</b> <code>cor()</code> for correlation</a></li>
<li class="chapter" data-level="3.3.2" data-path="week-3-correlation-and-causation.html"><a href="week-3-correlation-and-causation.html#correlation-exercises"><i class="fa fa-check"></i><b>3.3.2</b> Correlation exercises</a></li>
<li class="chapter" data-level="3.3.3" data-path="week-3-correlation-and-causation.html"><a href="week-3-correlation-and-causation.html#real-data"><i class="fa fa-check"></i><b>3.3.3</b> Real data</a></li>
<li class="chapter" data-level="3.3.4" data-path="week-3-correlation-and-causation.html"><a href="week-3-correlation-and-causation.html#theory-exercises"><i class="fa fa-check"></i><b>3.3.4</b> Theory exercises</a></li>
<li class="chapter" data-level="3.3.5" data-path="week-3-correlation-and-causation.html"><a href="week-3-correlation-and-causation.html#data-exercise"><i class="fa fa-check"></i><b>3.3.5</b> Data exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="week-4-chance-and-probability-theory.html"><a href="week-4-chance-and-probability-theory.html"><i class="fa fa-check"></i><b>4</b> Week 4: Chance and Probability Theory</a><ul>
<li class="chapter" data-level="4.1" data-path="week-4-chance-and-probability-theory.html"><a href="week-4-chance-and-probability-theory.html#general-goals-3"><i class="fa fa-check"></i><b>4.1</b> General Goals</a></li>
<li class="chapter" data-level="4.2" data-path="week-4-chance-and-probability-theory.html"><a href="week-4-chance-and-probability-theory.html#part-one-correlation-and-random-chance"><i class="fa fa-check"></i><b>4.2</b> Part one: Correlation and random chance</a><ul>
<li class="chapter" data-level="4.2.1" data-path="week-4-chance-and-probability-theory.html"><a href="week-4-chance-and-probability-theory.html#chance-exercises"><i class="fa fa-check"></i><b>4.2.1</b> Chance exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="lab-4-normal-distribution-central-limit-theorem.html"><a href="lab-4-normal-distribution-central-limit-theorem.html"><i class="fa fa-check"></i><b>5</b> Lab 4: Normal Distribution &amp; Central Limit Theorem</a><ul>
<li class="chapter" data-level="5.1" data-path="lab-4-normal-distribution-central-limit-theorem.html"><a href="lab-4-normal-distribution-central-limit-theorem.html#general-goals-4"><i class="fa fa-check"></i><b>5.1</b> General Goals</a></li>
<li class="chapter" data-level="5.2" data-path="lab-4-normal-distribution-central-limit-theorem.html"><a href="lab-4-normal-distribution-central-limit-theorem.html#r"><i class="fa fa-check"></i><b>5.2</b> R</a><ul>
<li class="chapter" data-level="5.2.1" data-path="lab-4-normal-distribution-central-limit-theorem.html"><a href="lab-4-normal-distribution-central-limit-theorem.html#generating-numbers-in-r"><i class="fa fa-check"></i><b>5.2.1</b> Generating Numbers in R</a></li>
<li class="chapter" data-level="5.2.2" data-path="lab-4-normal-distribution-central-limit-theorem.html"><a href="lab-4-normal-distribution-central-limit-theorem.html#sampling-distribution-of-the-mean."><i class="fa fa-check"></i><b>5.2.2</b> sampling distribution of the mean.</a></li>
<li class="chapter" data-level="5.2.3" data-path="lab-4-normal-distribution-central-limit-theorem.html"><a href="lab-4-normal-distribution-central-limit-theorem.html#sampling-distributions-for-any-statistic"><i class="fa fa-check"></i><b>5.2.3</b> Sampling distributions for any statistic</a></li>
<li class="chapter" data-level="5.2.4" data-path="lab-4-normal-distribution-central-limit-theorem.html"><a href="lab-4-normal-distribution-central-limit-theorem.html#central-limit-theorem"><i class="fa fa-check"></i><b>5.2.4</b> Central limit theorem</a></li>
<li class="chapter" data-level="5.2.5" data-path="lab-4-normal-distribution-central-limit-theorem.html"><a href="lab-4-normal-distribution-central-limit-theorem.html#the-normal-distribution"><i class="fa fa-check"></i><b>5.2.5</b> The normal distribution</a></li>
<li class="chapter" data-level="5.2.6" data-path="lab-4-normal-distribution-central-limit-theorem.html"><a href="lab-4-normal-distribution-central-limit-theorem.html#z-scores"><i class="fa fa-check"></i><b>5.2.6</b> z-scores</a></li>
<li class="chapter" data-level="5.2.7" data-path="lab-4-normal-distribution-central-limit-theorem.html"><a href="lab-4-normal-distribution-central-limit-theorem.html#generalization-exercise"><i class="fa fa-check"></i><b>5.2.7</b> Generalization Exercise</a></li>
<li class="chapter" data-level="5.2.8" data-path="lab-4-normal-distribution-central-limit-theorem.html"><a href="lab-4-normal-distribution-central-limit-theorem.html#writing-assignment"><i class="fa fa-check"></i><b>5.2.8</b> Writing assignment</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="lab-4-normal-distribution-central-limit-theorem.html"><a href="lab-4-normal-distribution-central-limit-theorem.html#excel"><i class="fa fa-check"></i><b>5.3</b> Excel</a></li>
<li class="chapter" data-level="5.4" data-path="lab-4-normal-distribution-central-limit-theorem.html"><a href="lab-4-normal-distribution-central-limit-theorem.html#spss"><i class="fa fa-check"></i><b>5.4</b> SPSS</a><ul>
<li class="chapter" data-level="5.4.1" data-path="lab-4-normal-distribution-central-limit-theorem.html"><a href="lab-4-normal-distribution-central-limit-theorem.html#saving-data-as-standardized-values."><i class="fa fa-check"></i><b>5.4.1</b> Saving data as standardized values.</a></li>
<li class="chapter" data-level="5.4.2" data-path="lab-4-normal-distribution-central-limit-theorem.html"><a href="lab-4-normal-distribution-central-limit-theorem.html#computing-variables"><i class="fa fa-check"></i><b>5.4.2</b> Computing variables</a></li>
<li class="chapter" data-level="5.4.3" data-path="lab-4-normal-distribution-central-limit-theorem.html"><a href="lab-4-normal-distribution-central-limit-theorem.html#practice-problems"><i class="fa fa-check"></i><b>5.4.3</b> Practice Problems</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="lab-4-normal-distribution-central-limit-theorem.html"><a href="lab-4-normal-distribution-central-limit-theorem.html#jamovi"><i class="fa fa-check"></i><b>5.5</b> JAMOVI</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>6</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Lab manual QuantRMA</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lab-4-normal-distribution-central-limit-theorem" class="section level1">
<h1><span class="header-section-number"> 5</span> Lab 4: Normal Distribution &amp; Central Limit Theorem</h1>
<script>
$("#coverpic").hide();
</script>
<p><span class="newthought">
By a small sample, we may judge of the whole piece.
—Miguel de Cervantes from Don Quixote
</span></p>
<div id="general-goals-4" class="section level2">
<h2><span class="header-section-number">5.1</span> General Goals</h2>
<ol style="list-style-type: decimal">
<li>Distributions</li>
<li>Sampling from distributions</li>
<li>Sampling distribution of the mean</li>
<li>Sampling statistics (statistics of many samples)</li>
<li>Central limit theorem</li>
<li>Normal Distribution</li>
<li>z-scores</li>
</ol>
</div>
<div id="r" class="section level2">
<h2><span class="header-section-number">5.2</span> R</h2>
<p>This is one of two special labs where we don’t use too much real data. We will mostly fake everything. Yes, you will learn how to fake data in this course. Be a superhero, and only use these skills for good and not for evil.</p>
<p>As we progress through the course, you will learn that generating simulated data can be very useful to help you understand real data. In fact, I will say this right now. If you can’t simulate the data you expect to find, then you probably can’t understand the data that you do find very well. That’s a bold statement. It’s probably partly true.</p>
<div id="generating-numbers-in-r" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Generating Numbers in R</h3>
<p>There are many ways to make R generate numbers for you. In all cases you define how the numbers are generated. We’ll go through a few of the many ways.</p>
<div id="sample" class="section level4">
<h4><span class="header-section-number">5.2.1.1</span> sample</h4>
<p>The sample function is like an endless gumball machine. You put the gumballs inside with different properties, say As and Bs, and then you let sample endlessly take gumballs out. Check it out:</p>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb195-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb195-1"></a>gumballs &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A&quot;</span>,<span class="st">&quot;B&quot;</span>)</span>
<span id="cb195-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb195-2"></a>sample_of_gumballs &lt;-<span class="kw">sample</span>(gumballs, <span class="dv">10</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)</span>
<span id="cb195-3"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb195-3"></a>sample_of_gumballs</span></code></pre></div>
<pre><code>##  [1] &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot;</code></pre>
<p>Here the sample function randomly picks A or B each time. We set it do this 10 times, so our sample has 10 things in it. We set <code>replace=TRUE</code> so that after each sample, we put the item back into the gumball machine and start again. Here’s another example with numbers</p>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb197-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb197-1"></a>some_numbers &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">5</span>)</span>
<span id="cb197-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb197-2"></a>sample_of_numbers &lt;-<span class="kw">sample</span>(some_numbers, <span class="dv">20</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)</span>
<span id="cb197-3"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb197-3"></a>sample_of_numbers</span></code></pre></div>
<pre><code>##  [1] 2 5 5 5 4 1 5 5 5 5 5 5 3 3 3 5 5 5 1 2</code></pre>
<p>Let’s do one more thing with sample. Let’s sample 1000 times from our <code>some_numbers</code> variable, and then look at the histogram</p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb199-1"></a><span class="kw">library</span>(ggplot2)</span>
<span id="cb199-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb199-2"></a>some_numbers &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">5</span>)</span>
<span id="cb199-3"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb199-3"></a>sample_of_numbers &lt;-<span class="kw">sample</span>(some_numbers, <span class="dv">1000</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)</span>
<span id="cb199-4"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb199-4"></a><span class="kw">hist</span>(sample_of_numbers)</span></code></pre></div>
<p><img src="quantrma_lab_files/figure-html/unnamed-chunk-89-1.png" width="672" /></p>
<p>We are looking at lots of samples from our little gumball machine of numbers. We put more 5s in, and voila, more 5s come out of in our big sample of 1000.</p>
</div>
<div id="runif-uniform-distribution" class="section level4">
<h4><span class="header-section-number">5.2.1.2</span> runif uniform distribution</h4>
<p>We can sample random numbers between any range using the <code>runif(n, min=0, max = 1)</code> function for the uniform distribution. We discussed this in the textbook. A uniform distribution is flat, and all the numbers between the min and max should occur roughly equally frequently. Let’s take 1000 random numbers between 0 and 1 and plot the histogram. We’ll just do it all in one line for speed.</p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb200-1"></a><span class="kw">hist</span>(<span class="kw">runif</span>(<span class="dv">1000</span>,<span class="dv">0</span>,<span class="dv">1</span>))</span></code></pre></div>
<p><img src="quantrma_lab_files/figure-html/unnamed-chunk-90-1.png" width="672" /></p>
<p>This is histogram is flattish. Not perfectly flat, after all we only took 1000 samples. What if we took many more, say 10,000 total samples? Now it looks more flat, each bin is occurring about 500 times each, which is pretty close to the same amount.</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb201-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb201-1"></a><span class="kw">hist</span>(<span class="kw">runif</span>(<span class="dv">10000</span>,<span class="dv">0</span>,<span class="dv">1</span>))</span></code></pre></div>
<p><img src="quantrma_lab_files/figure-html/unnamed-chunk-91-1.png" width="672" /></p>
</div>
<div id="rbinom-the-binomial-distribution" class="section level4">
<h4><span class="header-section-number">5.2.1.3</span> rbinom the binomial distribution</h4>
<p>The binomial distribution sounds like a scary word… binomial (AAGGGGHHHHH, stay away!). The binomial can be a coin flipping distribution. You use <code>rbinom(n, size, prob)</code>. <code>n</code> gives the number of samples you want to take. We’ll keep <code>size = 1</code> for now, it’s the number of trials (forget this for now, it’s more useful for more complicated things than what we are doing, if you want to know what it does, try it out, and see if you figure it out). <code>prob</code> is a little list you make of probabilities, that define how often certain things happen.</p>
<p>For example, consider flipping a coin. It will be heads or tails, and the coin, if it is fair, should have a 50% chance of being heads or tails. Here’s how we flip a coin 10 times using <code>rbinom</code>.</p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb202-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb202-1"></a>coin_flips &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="dv">10</span>,<span class="dv">1</span>,.<span class="dv">5</span>)</span>
<span id="cb202-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb202-2"></a>coin_flips</span></code></pre></div>
<pre><code>##  [1] 0 0 0 1 1 1 1 0 1 0</code></pre>
<p>We get a bunch of 0s, and 1s. We can pretend 0 = tails, and 1 = heads. Great, now we can do coin flipping if we want. For example, if you flip 10 coins, how many heads do you get? We can can do the above again, and then <code>sum(coin_flips)</code>. All the 1s are heads, so it will work out.</p>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb204-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb204-1"></a>coin_flips &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="dv">10</span>,<span class="dv">1</span>,.<span class="dv">5</span>)</span>
<span id="cb204-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb204-2"></a><span class="kw">sum</span>(coin_flips)</span></code></pre></div>
<pre><code>## [1] 5</code></pre>
<p>Alright, so we get the sum, which tells us the number of heads. But, should we always get that number of heads if we flipped a coin 10 times? If you keep redoing the above, you’ll get different answers. 5 heads will be the most frequent answer, but you will get lots of other answers too.</p>
<p>Hold on to your seats for this next one. With R, we can simulate the flipping of a coin 10 times (you already know that, you just did it), and we can do that over and over as many times as we want. For example, we could do it 100 times over, saving the number of heads for each set of 10 flips. Then we could look at the distribution of those sums. That would tell us about the range of things that can happen when we flip a coin 10 times. We can do that in loop like this:</p>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb206-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb206-1"></a>save_number_of_heads&lt;-<span class="kw">length</span>(<span class="dv">1000</span>) <span class="co"># make an empty variable to save things in</span></span>
<span id="cb206-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb206-2"></a></span>
<span id="cb206-3"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb206-3"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>){</span>
<span id="cb206-4"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb206-4"></a>  save_number_of_heads[i] &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">rbinom</span>(<span class="dv">10</span>,<span class="dv">1</span>,.<span class="dv">5</span>))</span>
<span id="cb206-5"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb206-5"></a>}</span>
<span id="cb206-6"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb206-6"></a></span>
<span id="cb206-7"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb206-7"></a><span class="kw">hist</span>(save_number_of_heads)</span></code></pre></div>
<p><img src="quantrma_lab_files/figure-html/unnamed-chunk-94-1.png" width="672" /></p>
<p>See, that wasn’t too painful. Now we see another histogram. The histogram shows us the frequency observing different numbers of heads (for 10 flips) across the 1000 simulations. 5 happens the most, but 2 happens sometimes, and so does 8. All of the possibilities seem to happen sometimes, some more than others.</p>
</div>
<div id="rnorm-the-normal-distribution" class="section level4">
<h4><span class="header-section-number">5.2.1.4</span> rnorm the normal distribution</h4>
<p>We’ll quickly show how to use <code>rnorm(n, mean=0, sd=1)</code> to sample numbers from a normal distribution. And, then we’ll come back to the normal distribution later, because it is so important.</p>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb207-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb207-1"></a><span class="kw">hist</span>(<span class="kw">rnorm</span>(<span class="dv">10000</span>,<span class="dv">0</span>,<span class="dv">1</span>))</span></code></pre></div>
<p><img src="quantrma_lab_files/figure-html/unnamed-chunk-95-1.png" width="672" /></p>
<p>There it is, a bell-shaped normal distribution with a mean of 0, and a standard deviation of 1. You’ve probably seen things like this before. Now you can sample numbers from normal distributions with any mean or standard deviation, just by changing those parts of the <code>rnorm</code> function.</p>
</div>
<div id="mixing-it-up" class="section level4">
<h4><span class="header-section-number">5.2.1.5</span> mixing it up</h4>
<p>The r functions are like Legos, you can put them together and come up with different things. What if wanted to sample from a distribution that looked like a two-humped camel’s back? Just sample from <code>rnorm</code> twice like this… mix away.</p>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb208-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb208-1"></a><span class="kw">hist</span>( <span class="kw">c</span>( <span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">25</span>,<span class="dv">5</span>), <span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">50</span>,<span class="dv">5</span>)) )</span></code></pre></div>
<p><img src="quantrma_lab_files/figure-html/unnamed-chunk-96-1.png" width="672" /></p>
</div>
<div id="summary" class="section level4">
<h4><span class="header-section-number">5.2.1.6</span> summary</h4>
<p>You can generate as many numbers as your computer can handle with R. PSA: Don’t ask R to generate a bajillion numbers or it will explode (or more likely just crash, probably won’t explode, that’s a metaphor).</p>
</div>
</div>
<div id="sampling-distribution-of-the-mean." class="section level3">
<h3><span class="header-section-number">5.2.2</span> sampling distribution of the mean.</h3>
<p>Remember the sampling distribution of the sample means from the textbook? Now, you will see the R code that made the graphs from before. As we’ve seen, we can take samples from distributions in R. We can take as many as we want. We can set our sample-size to be anything we want. And, we can take multiple samples of the same size as many times as we want.</p>
<div id="taking-multiple-samples-of-the-same-size" class="section level4">
<h4><span class="header-section-number">5.2.2.1</span> Taking multiple samples of the same size</h4>
<p>Let’s take 10 samples from a normal distribution (mean = 0, and SD = 1). Let’s set the sample-size for each to be 20. Then, we’ll put them all in a data frame and look at 10 different histograms, one for each sample.</p>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb209-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb209-1"></a>scores &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">10</span><span class="op">*</span><span class="dv">20</span>,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb209-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb209-2"></a>samples &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>,<span class="dt">each=</span><span class="dv">20</span>)</span>
<span id="cb209-3"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb209-3"></a>my_df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(samples,scores)</span></code></pre></div>
<p>First, look at the new my_df data frame. You can see there is a column with numbers 1 to 10, these are the sample names. There are also 20 scores for each in the scores column. Let’s make histograms for each sample, so we can see what all of the samples look like:</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb210-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb210-1"></a><span class="kw">ggplot</span>(my_df, <span class="kw">aes</span>(<span class="dt">x=</span>scores))<span class="op">+</span></span>
<span id="cb210-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb210-2"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&quot;white&quot;</span>)<span class="op">+</span></span>
<span id="cb210-3"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb210-3"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>samples)<span class="op">+</span></span>
<span id="cb210-4"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb210-4"></a><span class="st">  </span><span class="kw">theme_classic</span>()</span></code></pre></div>
<p><img src="quantrma_lab_files/figure-html/unnamed-chunk-98-1.png" width="672" /></p>
<p>Notice, all of the samples do not have the same looking histogram. This is because of random sampling error. All of the samples are coming from the same normal distributions, but random chance makes each sample a little bit different (e.g., you don’t always get 5 heads and 5 tails when you flip a coin right)</p>
</div>
<div id="getting-the-means-of-the-samples" class="section level4">
<h4><span class="header-section-number">5.2.2.2</span> Getting the means of the samples</h4>
<p>Now, let’s look at the means of the samples, we will use <code>dplyr</code> to get the means for each sample, and put them in a table:</p>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb211-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb211-1"></a><span class="kw">library</span>(dplyr)</span>
<span id="cb211-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb211-2"></a></span>
<span id="cb211-3"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb211-3"></a>sample_means &lt;-<span class="st"> </span>my_df <span class="op">%&gt;%</span></span>
<span id="cb211-4"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb211-4"></a><span class="st">                </span><span class="kw">group_by</span>(samples) <span class="op">%&gt;%</span></span>
<span id="cb211-5"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb211-5"></a><span class="st">                </span><span class="kw">summarise</span>(<span class="dt">means=</span><span class="kw">mean</span>(scores))</span>
<span id="cb211-6"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb211-6"></a></span>
<span id="cb211-7"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb211-7"></a>knitr<span class="op">::</span><span class="kw">kable</span>(sample_means)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">samples</th>
<th align="right">means</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">0.2231490</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">-0.1593726</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">-0.0439788</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">-0.0296705</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">0.0883803</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">-0.2288539</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">-0.0374033</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">0.2112090</td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="right">0.3371392</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">-0.3610338</td>
</tr>
</tbody>
</table>
<p>So, those are the means of our samples. What should the means be? Well, we would hope they are estimating the mean of the distribution they came from, which was 0. Notice, the numbers are all not 0, but they are kind of close to 0.</p>
</div>
<div id="histogram-for-the-means-of-the-samples" class="section level4">
<h4><span class="header-section-number">5.2.2.3</span> histogram for the means of the samples</h4>
<p>What if we now plot these 10 means (of each of the samples) in their own distribution?</p>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb212-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb212-1"></a> <span class="kw">ggplot</span>(sample_means, <span class="kw">aes</span>(<span class="dt">x=</span>means))<span class="op">+</span></span>
<span id="cb212-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb212-2"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&quot;white&quot;</span>)<span class="op">+</span></span>
<span id="cb212-3"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb212-3"></a><span class="st">  </span><span class="kw">theme_classic</span>()</span></code></pre></div>
<p><img src="quantrma_lab_files/figure-html/unnamed-chunk-100-1.png" width="672" /></p>
<p>That is the distribution of the sample means. It doesn’t look like much eh? That’s because we only took 10 samples right.</p>
<p>Notice one more thing…What is the mean of our 10 sample means? This is a mean of means. Remember that.</p>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb213-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb213-1"></a><span class="kw">mean</span>(sample_means<span class="op">$</span>means)</span></code></pre></div>
<pre><code>## [1] -4.354046e-05</code></pre>
<p>Well, that’s pretty close to zero. Which is good. When we average over our samples, they better estimate the mean of the distribution they came from.</p>
</div>
<div id="simulating-the-distribution-of-sample-means" class="section level4">
<h4><span class="header-section-number">5.2.2.4</span> simulating the distribution of sample means</h4>
<p>Our histogram with 10 sample means looked kind of sad. Let’s give it some more friends. How about we repeat our little sampling experiment 1000 times.</p>
<p>Explain…We take 1000 samples. Each sample takes 20 scores from a normal distribution (mean=0, SD=1). Then we find the means of each sample (giving us 1000 sample means). Then, we plot that distribution.</p>
<div class="sourceCode" id="cb215"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb215-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb215-1"></a><span class="co"># get 1000 samples with 20 scores each</span></span>
<span id="cb215-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb215-2"></a></span>
<span id="cb215-3"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb215-3"></a>scores &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1000</span><span class="op">*</span><span class="dv">20</span>,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb215-4"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb215-4"></a>samples &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>,<span class="dt">each=</span><span class="dv">20</span>)</span>
<span id="cb215-5"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb215-5"></a>my_df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(samples,scores)</span>
<span id="cb215-6"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb215-6"></a></span>
<span id="cb215-7"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb215-7"></a><span class="co"># get the means of the samples</span></span>
<span id="cb215-8"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb215-8"></a></span>
<span id="cb215-9"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb215-9"></a>sample_means &lt;-<span class="st"> </span>my_df <span class="op">%&gt;%</span></span>
<span id="cb215-10"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb215-10"></a><span class="st">                </span><span class="kw">group_by</span>(samples) <span class="op">%&gt;%</span></span>
<span id="cb215-11"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb215-11"></a><span class="st">                </span><span class="kw">summarise</span>(<span class="dt">means=</span><span class="kw">mean</span>(scores))</span>
<span id="cb215-12"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb215-12"></a></span>
<span id="cb215-13"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb215-13"></a><span class="co"># make a histogram</span></span>
<span id="cb215-14"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb215-14"></a></span>
<span id="cb215-15"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb215-15"></a> <span class="kw">ggplot</span>(sample_means, <span class="kw">aes</span>(<span class="dt">x=</span>means))<span class="op">+</span></span>
<span id="cb215-16"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb215-16"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&quot;white&quot;</span>)<span class="op">+</span></span>
<span id="cb215-17"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb215-17"></a><span class="st">  </span><span class="kw">theme_classic</span>()</span></code></pre></div>
<p><img src="quantrma_lab_files/figure-html/unnamed-chunk-102-1.png" width="672" /></p>
<p>There, that looks more like a sampling distribution of the sample means. Notice it’s properties. It is centered on 0, which tells us that sample means are mostly around zero. It is also bell-shaped, like the normal distribution it came from. It is also quite narrow. The numbers on the x-axis don’t go much past -.5 to +.5.</p>
<p>We will use things like the sampling distribution of the mean to make inferences about what chance can do in your data later on in this course.</p>
</div>
</div>
<div id="sampling-distributions-for-any-statistic" class="section level3">
<h3><span class="header-section-number">5.2.3</span> Sampling distributions for any statistic</h3>
<p>Just for fun here are some different sampling distributions for different statistics. We will take a normal distribution with mean = 100, and standard deviation =20. Then, we’ll take lots of samples with n = 50 (50 observations per sample). We’ll save all of the sample statistics, then plot their histograms. We do the sample means, standard deviations, maximum values, and medians. Let’s do it.</p>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb216-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-1"></a>all_df&lt;-<span class="kw">data.frame</span>()</span>
<span id="cb216-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-2"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>){</span>
<span id="cb216-3"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-3"></a>  sample&lt;-<span class="kw">rnorm</span>(<span class="dv">50</span>,<span class="dv">100</span>,<span class="dv">20</span>)</span>
<span id="cb216-4"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-4"></a>  sample_mean&lt;-<span class="kw">mean</span>(sample)</span>
<span id="cb216-5"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-5"></a>  sample_sd&lt;-<span class="kw">sd</span>(sample)</span>
<span id="cb216-6"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-6"></a>  sample_max&lt;-<span class="kw">max</span>(sample)</span>
<span id="cb216-7"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-7"></a>  sample_median&lt;-<span class="kw">median</span>(sample)</span>
<span id="cb216-8"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-8"></a>  t_df&lt;-<span class="kw">data.frame</span>(i,sample_mean,sample_sd,sample_max,sample_median)</span>
<span id="cb216-9"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-9"></a>  all_df&lt;-<span class="kw">rbind</span>(all_df,t_df)</span>
<span id="cb216-10"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-10"></a>}</span>
<span id="cb216-11"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-11"></a></span>
<span id="cb216-12"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-12"></a><span class="kw">library</span>(ggpubr)</span>
<span id="cb216-13"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-13"></a>a&lt;-<span class="kw">ggplot</span>(all_df,<span class="kw">aes</span>(<span class="dt">x=</span>sample_mean))<span class="op">+</span></span>
<span id="cb216-14"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-14"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&quot;white&quot;</span>)<span class="op">+</span></span>
<span id="cb216-15"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-15"></a><span class="st">  </span><span class="kw">theme_classic</span>()</span>
<span id="cb216-16"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-16"></a>b&lt;-<span class="kw">ggplot</span>(all_df,<span class="kw">aes</span>(<span class="dt">x=</span>sample_sd))<span class="op">+</span></span>
<span id="cb216-17"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-17"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&quot;white&quot;</span>)<span class="op">+</span></span>
<span id="cb216-18"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-18"></a><span class="st">  </span><span class="kw">theme_classic</span>()</span>
<span id="cb216-19"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-19"></a>c&lt;-<span class="kw">ggplot</span>(all_df,<span class="kw">aes</span>(<span class="dt">x=</span>sample_max))<span class="op">+</span></span>
<span id="cb216-20"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-20"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&quot;white&quot;</span>)<span class="op">+</span></span>
<span id="cb216-21"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-21"></a><span class="st">  </span><span class="kw">theme_classic</span>()</span>
<span id="cb216-22"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-22"></a>d&lt;-<span class="kw">ggplot</span>(all_df,<span class="kw">aes</span>(<span class="dt">x=</span>sample_median))<span class="op">+</span></span>
<span id="cb216-23"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-23"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&quot;white&quot;</span>)<span class="op">+</span></span>
<span id="cb216-24"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-24"></a><span class="st">  </span><span class="kw">theme_classic</span>()</span>
<span id="cb216-25"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-25"></a></span>
<span id="cb216-26"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-26"></a><span class="kw">ggarrange</span>(a,b,c,d,</span>
<span id="cb216-27"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb216-27"></a>          <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">nrow =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="quantrma_lab_files/figure-html/unnamed-chunk-103-1.png" width="672" /></p>
<p>From reading the textbook and attending lecture, you should be able to start thinking about why these sampling statistic distributions might be useful…For now, just know that you can make a sampling statistic for pretty much anything in R, just by simulating the process of sampling, measuring the statistic, doing it over a bunch, and then plotting the histogram. This gives you a pretty good estimate of the distribution for that sampling statistic.</p>
</div>
<div id="central-limit-theorem" class="section level3">
<h3><span class="header-section-number">5.2.4</span> Central limit theorem</h3>
<p>We have been building you up for the central limit theorem, described in the textbook and in class. The central limit theorem is basically that the distribution of sample means will be a normal curve. We already saw that before. But, the interesting thing about it, is that the distribution of your sample means will be normal, even if the distribution the samples came from is not normal. Huh what?</p>
<p>To demonstrate this the next bit of code is modified from what we did earlier. We create 100 samples. Each sample has 1000 observations. All of them come from a uniform distribution between 0 to 1. This means all of the numbers between 0 and 1 should occur equally frequently. Below I plot histograms for the first 10 samples (out of the 100 total, 100 is too many to look at). Notice the histograms are not normal, they are roughly flat.</p>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb217-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb217-1"></a>scores &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">100</span><span class="op">*</span><span class="dv">1000</span>,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb217-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb217-2"></a>samples &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>,<span class="dt">each=</span><span class="dv">1000</span>)</span>
<span id="cb217-3"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb217-3"></a>my_df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(samples,scores)</span>
<span id="cb217-4"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb217-4"></a></span>
<span id="cb217-5"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb217-5"></a><span class="kw">ggplot</span>(my_df[<span class="dv">1</span><span class="op">:</span>(<span class="dv">10</span><span class="op">*</span><span class="dv">1000</span>),], <span class="kw">aes</span>(<span class="dt">x=</span>scores))<span class="op">+</span></span>
<span id="cb217-6"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb217-6"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&quot;white&quot;</span>, <span class="dt">bins=</span><span class="dv">10</span>)<span class="op">+</span></span>
<span id="cb217-7"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb217-7"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>samples)<span class="op">+</span></span>
<span id="cb217-8"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb217-8"></a><span class="st">  </span><span class="kw">theme_classic</span>()<span class="op">+</span></span>
<span id="cb217-9"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb217-9"></a><span class="st">  </span><span class="kw">ylim</span>(<span class="dv">0</span>,<span class="dv">200</span>)</span></code></pre></div>
<p><img src="quantrma_lab_files/figure-html/unnamed-chunk-104-1.png" width="672" /></p>
<p>We took samples from a flat uniform distribution, and the samples themselves look like that same flat distribution.</p>
<p>HOWEVER, if we now do the next step, and compute the means of each of our 100 samples, we could then look at the sampling distribution of the sample means. Let’s do that:</p>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb218-1"></a>sample_means &lt;-<span class="st"> </span>my_df <span class="op">%&gt;%</span></span>
<span id="cb218-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb218-2"></a><span class="st">                </span><span class="kw">group_by</span>(samples) <span class="op">%&gt;%</span></span>
<span id="cb218-3"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb218-3"></a><span class="st">                </span><span class="kw">summarise</span>(<span class="dt">means=</span><span class="kw">mean</span>(scores))</span>
<span id="cb218-4"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb218-4"></a></span>
<span id="cb218-5"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb218-5"></a><span class="co"># make a histogram</span></span>
<span id="cb218-6"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb218-6"></a></span>
<span id="cb218-7"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb218-7"></a> <span class="kw">ggplot</span>(sample_means, <span class="kw">aes</span>(<span class="dt">x=</span>means))<span class="op">+</span></span>
<span id="cb218-8"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb218-8"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&quot;white&quot;</span>, <span class="dt">bins=</span><span class="dv">15</span>)<span class="op">+</span></span>
<span id="cb218-9"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb218-9"></a><span class="st">  </span><span class="kw">theme_classic</span>()</span></code></pre></div>
<p><img src="quantrma_lab_files/figure-html/unnamed-chunk-105-1.png" width="672" /></p>
<p>As you can see, the sampling distribution of the sample means is not flat. It’s shaped kind of normal-ish. If we had taken many more samples, found their means, and then looked at a histogram, it would become even more normal looking. Because that’s what happens according to the central limit theorem.</p>
</div>
<div id="the-normal-distribution" class="section level3">
<h3><span class="header-section-number">5.2.5</span> The normal distribution</h3>
<p>“Why does any of this matter, why are we doing this, can we stop now!!!!!! PLEEEEAASSEE, somebody HELP”.</p>
<p>We are basically just repeating what was said in the textbook, and the lecture, so that you get the concept explained in a bunch of different ways. It will sink in.</p>
<p>The reason the central limit theorem is important, is because researchers often take many samples, then analyse the means of their samples. That’s what they do.</p>
<p>An experiment might have 20 people. You might take 20 measurements from each person. That’s taking 20 samples. Then, because we know that samples are noisy. We take the means of the samples.</p>
<p>So, what researchers are often looking at, (and you too, very soon) are means of samples. Not just the samples. And, now we know that means of samples (if we had a lot of samples), look like they are distributed normally (the central limit theorem says the should be).</p>
<p>We can use this knowledge. If we learn a little bit more about normal distributions, and how they behave and work, we can take that and use it to understand our sample means better. This will become more clear as head into the topic of statistical inference next week. This is all a build up for that.</p>
<p>To continue the build-up we now look at some more properties of the normal distribution.</p>
<div id="graphing-the-normal-distribution" class="section level4">
<h4><span class="header-section-number">5.2.5.1</span> Graphing the normal distribution</h4>
<p>“Wait, I thought we already did that”. We sort of did. We sampled numbers and made histograms that looked like normal distributions. But, a “normal distribution” is more of an abstract idea. It looks like this in the abstract:</p>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb219-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb219-1"></a>normal_dist &lt;-<span class="st"> </span><span class="kw">dnorm</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>,<span class="dv">4</span>,.<span class="dv">1</span>), <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb219-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb219-2"></a>values &lt;-<span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>,<span class="dv">4</span>,.<span class="dv">1</span>)</span>
<span id="cb219-3"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb219-3"></a>normal_df &lt;-<span class="kw">data.frame</span>(values,normal_dist)</span>
<span id="cb219-4"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb219-4"></a></span>
<span id="cb219-5"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb219-5"></a><span class="kw">ggplot</span>(normal_df, <span class="kw">aes</span>(<span class="dt">x=</span>values,<span class="dt">y=</span>normal_dist))<span class="op">+</span></span>
<span id="cb219-6"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb219-6"></a><span class="st">  </span><span class="kw">geom_line</span>()<span class="op">+</span></span>
<span id="cb219-7"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb219-7"></a><span class="st">  </span><span class="kw">theme_classic</span>()</span></code></pre></div>
<p><img src="quantrma_lab_files/figure-html/unnamed-chunk-106-1.png" width="672" /></p>
<p>A really nice shaped bell-like thing. This normal distribution has a mean of 0, and standard deviation of 1. The heights of the lines tell you roughly how likely each value is. Notice, it is centered on 0 (most likely that numbers from this distribution will be near 0), and it goes down as numbers get bigger or smaller (so bigger or smaller numbers get less likely). There is a range to it. Notice the values don’t go much beyond -4 and +4. This because those values don’t happen very often. Theoretically any value could happen, but really big or small values have really low probabilities.</p>
</div>
<div id="calculating-the-probability-of-specific-ranges." class="section level4">
<h4><span class="header-section-number">5.2.5.2</span> calculating the probability of specific ranges.</h4>
<p>We can use R to tell us about the probability of getting numbers in a certain range. For example, when you think about. It should be obvious that you have a 50% probability of getting the number 0 or greater. Half of the distribution is 0 or greater, so you have a 50% probability.</p>
<p>We can use the <code>pnorm</code> function to confirm this:</p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb220-1"></a><span class="kw">pnorm</span>(<span class="dv">0</span>, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd=</span> <span class="dv">1</span>, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 0.5</code></pre>
<p>Agreed, <code>pnorm</code> tells us the probability of getting 0 or greater is .5.</p>
<p>Well, what is the probability of getting a 2 or greater? That’s a bit harder to judge, obviously less than 50%. Use R like this to find out:</p>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb222-1"></a><span class="kw">pnorm</span>(<span class="dv">2</span>, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd=</span> <span class="dv">1</span>, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 0.02275013</code></pre>
<p>The probability of getting a 2 or greater is .0227 (not very probable)</p>
<p>What is the probability of getting a score between -1 and 1?</p>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb224-1"></a>ps&lt;-<span class="kw">pnorm</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd=</span> <span class="dv">1</span>, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)</span>
<span id="cb224-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb224-2"></a>ps[<span class="dv">1</span>]<span class="op">-</span>ps[<span class="dv">2</span>]</span></code></pre></div>
<pre><code>## [1] 0.6826895</code></pre>
<p>About 68%. About 68% of all the numbers would be between -1 and 1. So naturally, about 34% of the numbers would be between 0 and 1. Notice, we are just getting a feeling for this, you’ll see why in a bit when we do z-scores (some of you may realize we are already doing that…)</p>
<p>What about the numbers between 1 and 2?</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb226-1"></a>ps&lt;-<span class="kw">pnorm</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd=</span> <span class="dv">1</span>, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)</span>
<span id="cb226-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb226-2"></a>ps[<span class="dv">1</span>]<span class="op">-</span>ps[<span class="dv">2</span>]</span></code></pre></div>
<pre><code>## [1] 0.1359051</code></pre>
<p>About 13.5% of numbers fall in that range, not much.</p>
<p>How about between 2 and 3?</p>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb228-1"></a>ps&lt;-<span class="kw">pnorm</span>(<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>), <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd=</span> <span class="dv">1</span>, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)</span>
<span id="cb228-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb228-2"></a>ps[<span class="dv">1</span>]<span class="op">-</span>ps[<span class="dv">2</span>]</span></code></pre></div>
<pre><code>## [1] 0.02140023</code></pre>
<p>Again a very small amount, only 2.1 % of the numbers, not a a lot.</p>
</div>
<div id="summary-pnorm" class="section level4">
<h4><span class="header-section-number">5.2.5.3</span> summary pnorm</h4>
<p>You can always use <code>pnorm</code> to figure how the probabilities of getting certain values from any normal distribution. That’s great.</p>
</div>
</div>
<div id="z-scores" class="section level3">
<h3><span class="header-section-number">5.2.6</span> z-scores</h3>
<p>We just spent a bunch of time looking at a very special normal distribution, the one where the mean = 0, and the standard deviation = 1. Then we got a little bit comfortable with what those numbers mean. 0 happens a lot. Numbers between -1 and 1 happen a lot. Numbers bigger or smaller than 1 also happen fairly often, but less often. Number bigger than 2 don’t happen a lot, numbers bigger than 3 don’t happen hardly at all.</p>
<p>We can use this knowledge for our convenience. Often, we are not dealing with numbers exactly like these. For example, someone might say, I got a number, it’s 550. It came from a distribution with mean = 600, and standard deviation = 25. So, does 545 happen a lot or not? The numbers don’t tell you right away.</p>
<p>If we were talking about our handy distribution with mean = 0 and standard deviation = 1, and I told I got a number 4.5 from that distribution. You would automatically know that 4.5 doesn’t happen a lot. Right? Right!</p>
<p>z-scores are a way of transforming one set of numbers into our neato normal distribution, with mean = 0 and standard deviation = 1.</p>
<p>Here’s a simple example, like what we said in the textbook. If you have a normal distribution with mean = 550, and standard deviation 25, then how far from the mean is the number 575? It’s a whole 25 away (550+25 = 575). How many standard deviations is that? It’s 1 whole standard deviation. So does a number like 575 happen a lot? Well, based on what you know about normal distributions, 1 standard deviation of the mean isn’t that far, and it does happen fairly often. This is what we are doing here.</p>
<div id="calculating-z-scores" class="section level4">
<h4><span class="header-section-number">5.2.6.1</span> Calculating z-scores</h4>
<ol style="list-style-type: decimal">
<li>get some numbers</li>
</ol>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb230-1"></a>some_numbers &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">20</span>,<span class="dv">50</span>,<span class="dv">25</span>)</span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>Calculate the mean and standard deviation</li>
</ol>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb231-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb231-1"></a>my_mean &lt;-<span class="st"> </span><span class="kw">mean</span>(some_numbers)</span>
<span id="cb231-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb231-2"></a>my_sd &lt;-<span class="kw">sd</span>(some_numbers)</span>
<span id="cb231-3"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb231-3"></a></span>
<span id="cb231-4"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb231-4"></a><span class="kw">print</span>(my_mean)</span></code></pre></div>
<pre><code>## [1] 56.73814</code></pre>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb233-1"></a><span class="kw">print</span>(my_sd)</span></code></pre></div>
<pre><code>## [1] 19.00354</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>subtract the mean from your numbers</li>
</ol>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb235-1"></a>differences&lt;-some_numbers<span class="op">-</span>my_mean</span>
<span id="cb235-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb235-2"></a><span class="kw">print</span>(differences)</span></code></pre></div>
<pre><code>##  [1]  18.9090435 -15.2148834 -41.4015308 -19.4201692  -4.7524095   0.1452407
##  [7]  20.0769859  -2.5429101  -6.0408621  -7.1124419   9.3955392  27.7189604
## [13]   2.6017852  29.2505692 -36.0339221  17.4689415  -3.4019797  -5.2751557
## [19]  17.2465154  -1.6173164</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>divide by the standard deviation</li>
</ol>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb237-1"></a>z_scores&lt;-differences<span class="op">/</span>my_sd</span>
<span id="cb237-2"><a href="lab-4-normal-distribution-central-limit-theorem.html#cb237-2"></a><span class="kw">print</span>(z_scores)</span></code></pre></div>
<pre><code>##  [1]  0.99502717 -0.80063396 -2.17862147 -1.02192351 -0.25008016  0.00764282
##  [7]  1.05648636 -0.13381241 -0.31788080 -0.37426922  0.49440982  1.45862051
## [13]  0.13691052  1.53921647 -1.89616845  0.91924647 -0.17901816 -0.27758798
## [19]  0.90754202 -0.08510604</code></pre>
<p>Done. Now you have converted your original numbers into what we call standardized scores. They are standardized to have the same properties (assumed properties) as a normal distribution with mean = 0, and SD = 1.</p>
<p>You could look at each of your original scores, and try to figure out if they are likely or unlikely numbers. But, if you make them into z-scores, then you can tell right away. Numbers close to 0 happen a lot, bigger numbers closer to 1 happen less often, but still fairly often, and numbers bigger than 2 or 3 hardly happen at all.</p>
</div>
</div>
<div id="generalization-exercise" class="section level3">
<h3><span class="header-section-number">5.2.7</span> Generalization Exercise</h3>
<p>(1 point - Pass/Fail)</p>
<p>Complete the generalization exercise described in your R Markdown document for this lab.</p>
<ol style="list-style-type: decimal">
<li>Simulate the sampling distribution of the mean for sample-size =10, from a normal distribution with mean =100, and standard deviation = 25. Run the simulation 1000 times, taking 1000 samples, and computing the sample mean each time.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Plot the sampling distribution of the mean in a histogram</li>
<li>Report the mean of the sampling distribution of the mean</li>
<li>Report the standard deviation of the sampling distribution of the mean</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Repeat all of the above, except change the sample-size to 100 for all simulations</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Plot the sampling distribution of the mean in a histogram</li>
<li>Report the mean of the sampling distribution of the mean</li>
<li>Report the standard deviation of the sampling distribution of the mean</li>
</ol>
</div>
<div id="writing-assignment" class="section level3">
<h3><span class="header-section-number">5.2.8</span> Writing assignment</h3>
<p>(2 points - Graded)</p>
<p>Complete the writing assignment described in your R Markdown document for this lab. When you have finished everything. Knit the document and hand in your stuff (you can submit your .RMD file to blackboard if it does not knit.)</p>
<ol style="list-style-type: decimal">
<li><p>Explain the concept of sampling error (1 point)</p></li>
<li><p>Explain why the standard deviation of the sampling distribution of mean gets smaller as sample-size increases (1 point)</p></li>
</ol>
<p>General grading.</p>
<ul>
<li>You must write in complete sentences. Point form sentences will be given 0 points.</li>
<li>Completely incorrect answers will receive 0 points.</li>
<li>If your answer is generally correct but very difficult to understand and unclear you may receive half points for the question</li>
</ul>
</div>
</div>
<div id="excel" class="section level2">
<h2><span class="header-section-number">5.3</span> Excel</h2>
<p>How to do it in Excel</p>
</div>
<div id="spss" class="section level2">
<h2><span class="header-section-number">5.4</span> SPSS</h2>
<p>In this lab, we will use SPSS to transform a set of raw data into z-scores using two methods:</p>
<ol style="list-style-type: decimal">
<li>Saving data as standardized values</li>
<li>Computing a new variable manually</li>
</ol>
<p>Let’s first begin with a short data set we will enter into a new SPSS data spreadsheet. Let’s use the following data set: {x= 1, 3, 2, 5, 4, 6, 5, 8, 9}. Enter these into SPSS and name them appropriately.</p>
<pre><code>## Error in knitr::include_graphics(&quot;img/4.4.11.png&quot;): Cannot find the file(s): &quot;img/4.4.11.png&quot;</code></pre>
<div id="saving-data-as-standardized-values." class="section level3">
<h3><span class="header-section-number">5.4.1</span> Saving data as standardized values.</h3>
<hr />
<p>This method is a quick and simple way to turn a set of scores in raw format into z-scores. First, go to <span style="color:blue">Analyze</span>, then <span style="color:blue">Descriptive Statistics</span>, then <span style="color:blue">Descriptives</span>:</p>
<pre><code>## Error in knitr::include_graphics(&quot;img/4.4.12.png&quot;): Cannot find the file(s): &quot;img/4.4.12.png&quot;</code></pre>
<p>A window will appear, asking for you to specify for which variable you would like descriptive statistics. Move the <code>x</code> variable into the right field using the arrow. Then, make sure to check off <span style="color:blue">Save standardized values as variables</span>:</p>
<pre><code>## Error in knitr::include_graphics(&quot;img/4.4.13.png&quot;): Cannot find the file(s): &quot;img/4.4.13.png&quot;</code></pre>
<p>Now, click <span style="color:blue">Ok</span>.</p>
<p>SPSS will produce an output table containing some basic descriptive statistics for the <code>x</code> variable:</p>
<pre><code>## Error in knitr::include_graphics(&quot;img/4.4.14.png&quot;): Cannot find the file(s): &quot;img/4.4.14.png&quot;</code></pre>
<p>However, you can ignore this window for now. Go back to data view in your spreadsheet and you will notice a new column of data (a new variable) as been created called <code>Zx</code>. This variable contains the z-scores that correspond to the values in the <code>x</code> columm:</p>
<pre><code>## Error in knitr::include_graphics(&quot;img/4.4.15.png&quot;): Cannot find the file(s): &quot;img/4.4.15.png&quot;</code></pre>
</div>
<div id="computing-variables" class="section level3">
<h3><span class="header-section-number">5.4.2</span> Computing variables</h3>
<hr />
<p>If you use the method shown above to convert a set of measurements to z-scores, you don’t need to use this method to do the same thing. However, computing new variables may be useful for more than just converting scores to z-scores, so it’s worth illustrating as well. The take-away message here is that you can use SPSS to create new variables based on existing ones.</p>
<p>To illustrate how this is done, let’s work with the data sheet we used in the previous example. Currently, it includes a column for our x variable, and the new <code>Zx</code> variable we created using the Analyze &gt; Descriptive Statistics &gt; Descriptives menu.</p>
<pre><code>## Error in knitr::include_graphics(&quot;img/4.4.15.png&quot;): Cannot find the file(s): &quot;img/4.4.15.png&quot;</code></pre>
<p>This time, we are going to turn our x variable measurements into z-scores manually. In order to do this, we’re going to need the necessary components to calculate z-scores: We will need the mean and standard deviation of the <code>x</code> variable. Remember, in the previous section a table of descriptive statistics was generated:</p>
<pre><code>## Error in knitr::include_graphics(&quot;img/4.4.14.png&quot;): Cannot find the file(s): &quot;img/4.4.14.png&quot;</code></pre>
<p>We know that the mean of variable <code>x</code> is 4.78 and the standard deviation is 2.635. In order to turn every measurement in variable <code>x</code> into a z-score, then, we must subtract 4.78 from each <code>x</code>, then divide that difference by 2.635. We are going to ask SPSS to do this by going to the <span style="color:blue">Transform</span> menu, and then selecting <span style="color:blue">Compute Variable</span>.</p>
<pre><code>## Error in knitr::include_graphics(&quot;img/4.4.16.png&quot;): Cannot find the file(s): &quot;img/4.4.16.png&quot;</code></pre>
<p>This will open the Compute window:</p>
<pre><code>## Error in knitr::include_graphics(&quot;img/4.4.17.png&quot;): Cannot find the file(s): &quot;img/4.4.17.png&quot;</code></pre>
<p>Here, let’s first enter a name for the new variable we’re about to create. In the field labeled “Target Variable”, enter a name for your new variable. Let’s try <code>new_z</code> as the name.</p>
<p>Next, in the field labeled “Numeric Expression”, we will specify the calculation to be made. Because I want SPSS to take the variable <code>x</code>, subtract 4.78 from it, and then divide this difference by 2.635, I am going to type in this formula:
1. First, type in an open parenthesis
2. Second, select <code>x</code> from the field on the left and move it to the “Numeric Expression” field using the arrow.
3. Type a minus sign, followed by 4.78
4. Type in a closed parenthesis.
5. Type in a backslash “/” (this specifies division)
6. Type in the standard deviation, 2.635</p>
<p>Your Compute window should now look like this:</p>
<pre><code>## Error in knitr::include_graphics(&quot;img/4.4.18.png&quot;): Cannot find the file(s): &quot;img/4.4.18.png&quot;</code></pre>
<p>Now, click <span style="color:blue">OK</span>. SPSS will generate a blank output window that confirms you have computed a variable. You may minimize or close this window and go back to your SPSS spreadsheet. It should now have a new variable listed, <code>new_z</code>, and the computed z-scores should look very similar to the previously calculated z-scores (any differences are due to using rounded figures):</p>
<pre><code>## Error in knitr::include_graphics(&quot;img/4.4.19.png&quot;): Cannot find the file(s): &quot;img/4.4.19.png&quot;</code></pre>
<p>You can use this Compute Variable window to calculate z-scores or make any calculations using existing variables.</p>
</div>
<div id="practice-problems" class="section level3">
<h3><span class="header-section-number">5.4.3</span> Practice Problems</h3>
<hr />
<p>“Professor, do you grade on a curve?”</p>
<p>This is probably the most commonly-asked question in Statistics class. Everyone assumes that grading on a curve will benefit them. But does it?</p>
<p><a href="https://github.com/CrumpLab/statisticsLab/blob/master/data/spssdata/StatsGrades.sav">Here</a> is a link to an SPSS file containing 50 students’ exam grades (let’s say it’s the final exam for a Statistics class).</p>
<ol style="list-style-type: decimal">
<li><p>Create a table containing the mean and standard deviation for this sample of scores. Now, produce a frequency histogram of the score data. Describe the distribution.</p></li>
<li><p>Transform each student’s score into a Z-score (you can use either method shown in this tutorial). Now, plot the frequency histogram of this Z-score distribution. Compare it to the raw score distribution. How are they the same? How are they different?</p></li>
<li><p>Imagine you are a student in this class who received a 90 on this exam. However, the Professor has decided to GRADE ON A CURVE (shock! awe!), such that only the top 10% of the class receives an A (this professor only gives whole grades, no minuses or pluses). Calculate the z-score that corresponds to a raw score of 90 on this exam. Will you get an A with this grade? Why or why not?</p></li>
</ol>
</div>
</div>
<div id="jamovi" class="section level2">
<h2><span class="header-section-number">5.5</span> JAMOVI</h2>
<p>How to do it in JAMOVI</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="week-4-chance-and-probability-theory.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
